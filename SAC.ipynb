{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2601a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import namedtuple, deque\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tqdm\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf163657",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f9a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much we value entropy / exploration.\n",
    "ALPHA_TARGET = 0.8 * log(env.action_space.n)            \n",
    "GAMMA = 1 - 0.01        # How much we value future rewards.\n",
    "TAU = 0.01              # How much q_target is updated when polyak averaging (step 15).\n",
    "POLICY_LR = 0.001       # Policy learning rate.\n",
    "Q_LR = 0.001            # Q learning rate.\n",
    "ALPHA_LR = 0.001        # ALPHA learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89982995",
   "metadata": {},
   "outputs": [],
   "source": [
    "SARS = namedtuple('SARS', 'state, action, reward, next_state, t, failed, limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2cd7e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=0)\n",
    "input = torch.tensor([1, 2, 3], dtype=float)\n",
    "display(input)\n",
    "output = softmax(input)\n",
    "display(output)\n",
    "sum(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10ba09d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [3., 3., 3.]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652],\n",
       "        [0.3333, 0.3333, 0.3333]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5134, 0.8228, 1.6638], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "input = torch.tensor([[1, 2, 3], [1, 2, 3], [3, 3, 3]], dtype=float)\n",
    "display(input)\n",
    "output = softmax(input)\n",
    "display(output)\n",
    "sum(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e24dbb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, 1500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1500, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        nn_out = self.linear_relu_stack(x)\n",
    "        return nn.Softmax(dim=1)(nn_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        raise RuntimeError(\"Use forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357a97db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=2000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2000, out_features=1500, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1500, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_network = PolicyNetwork(4, 2)\n",
    "policy_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8763d75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c65c4c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57f14cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3078, 0.6021, 0.3211, 0.2887],\n",
       "        [0.9162, 0.7242, 0.0650, 0.2726],\n",
       "        [0.2618, 0.4330, 0.6682, 0.1590],\n",
       "        [0.7153, 0.4364, 0.7828, 0.2448],\n",
       "        [0.6267, 0.6807, 0.8945, 0.8965]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_states = torch.rand(5, 4)\n",
    "mock_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf6c7db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5105, 0.4895],\n",
       "        [0.5101, 0.4899],\n",
       "        [0.5091, 0.4909],\n",
       "        [0.5157, 0.4843],\n",
       "        [0.5201, 0.4799]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_network.forward(mock_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d287d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, 1500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1500, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        nn_out = self.linear_relu_stack(x)\n",
    "        return nn_out\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        raise RuntimeError(\"Use forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a80af706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=2000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2000, out_features=1500, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1500, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_network = QNetwork(4, 2)\n",
    "q_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e7c0e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0883, -0.1147],\n",
       "        [ 0.1121, -0.1403],\n",
       "        [ 0.1029, -0.1290],\n",
       "        [ 0.1185, -0.1729],\n",
       "        [ 0.1125, -0.2135]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_network.forward(mock_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aeb9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(action_f, step_f, env, policy):\n",
    "    episode_reward = 0\n",
    "    s, info = env.reset()\n",
    "    for t in itertools.count(start=1):\n",
    "        a = action_f(policy, s)\n",
    "        next_state, reward, failed, limit, info = env.step(a)\n",
    "        episode_reward += reward\n",
    "        assert t <= env._max_episode_steps\n",
    "        assert not (failed and limit)\n",
    "        step_f(s, a, reward, next_state, t, failed, limit)\n",
    "        if failed or limit:\n",
    "            break\n",
    "        s = next_state\n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e867c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    def __init__(self, env_state_size, env_action_space_size):\n",
    "        self.policy_network = PolicyNetwork(env_state_size, env_action_space_size)\n",
    "        self.q1_network = QNetwork(env_state_size, env_action_space_size)\n",
    "        self.q2_network = QNetwork(env_state_size, env_action_space_size)\n",
    "        self.q1_target_network = deepcopy(self.q1_network)\n",
    "        self.q2_target_network = deepcopy(self.q2_network)\n",
    "        self.alpha = torch.tensor(ALPHA_TARGET, dtype=float, requires_grad=True)\n",
    "        self.policy_network.to(device)\n",
    "        self.q1_network.to(device)\n",
    "        self.q2_network.to(device)\n",
    "        self.q1_target_network.to(device)\n",
    "        self.q2_target_network.to(device)\n",
    "        self.alpha.to(device)\n",
    "        self.reset_optimizers()\n",
    "\n",
    "    def reset_optimizers(self):\n",
    "        self.policy_optimizer = torch.optim.SGD(self.policy_network.parameters(), lr=POLICY_LR)\n",
    "        self.q1_optimizer = torch.optim.SGD(self.q1_network.parameters(), lr=Q_LR)\n",
    "        self.q2_optimizer = torch.optim.SGD(self.q2_network.parameters(), lr=Q_LR)\n",
    "\n",
    "    @property\n",
    "    def alpha_dc(self):\n",
    "        \"\"\"Alpha, (D)etached and (C)lamped\"\"\"\n",
    "        return self.alpha.detach().clamp(min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "258ee690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., dtype=torch.float64, requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor(1, dtype=float, requires_grad=True)\n",
    "display(t)\n",
    "torch.optim.SGD([t], lr=ALPHA_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2ef4891",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = deque(maxlen=30_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3835dfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3d9ddd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "856e3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "oss = env.observation_space.shape\n",
    "if len(oss) != 1:\n",
    "    raise RuntimeError(f'Unknown observation_space.shape: {oss}')\n",
    "os_len = oss[0]\n",
    "policy = Policy(os_len, env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26178da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00466385,  1.4123211 ,  0.4723712 ,  0.06226536, -0.00539734,\n",
       "       -0.10699912,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, info = env.reset()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c20fffdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0047,  1.4123,  0.4724,  0.0623, -0.0054, -0.1070,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.tensor(s).reshape((1, -1))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8200ac15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2569, 0.2318, 0.2781, 0.2332]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_output = policy.policy_network.forward(s.to(device))\n",
    "policy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3eb4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_weights = policy_output.reshape((-1,)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "481df43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b78db85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = random.choices(range(len(action_weights)), weights=action_weights)[0]\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a11637db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(policy, s):\n",
    "    tensor_s = torch.tensor(s).reshape((1, -1)).to(device)\n",
    "    action_weights = policy.policy_network.forward(tensor_s).reshape((-1,)).tolist()\n",
    "    action = random.choices(range(len(action_weights)), weights=action_weights)[0]\n",
    "    return action\n",
    "\n",
    "def step(initial_s, a, r, next_s, t, failed, limit):\n",
    "    replay_buffer.append(SARS(initial_s, a, r, next_s, t, failed, limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b642f7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devjac/Code/python/learn-pytorch/.venv/learn-pytorch/lib64/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:249: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-91.20855692557728"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_episode(action, step, env, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9107af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e377098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([SARS(state=array([-0.00549459,  1.4016852 , -0.5565525 , -0.41045275,  0.0063736 ,\n",
       "               0.12606737,  0.        ,  0.        ], dtype=float32), action=2, reward=2.266187979900633, next_state=array([-0.01100483,  1.3934011 , -0.5572752 , -0.36822054,  0.01256057,\n",
       "               0.12375202,  0.        ,  0.        ], dtype=float32), t=1, failed=False, limit=False),\n",
       "       SARS(state=array([-0.01100483,  1.3934011 , -0.5572752 , -0.36822054,  0.01256057,\n",
       "               0.12375202,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.44508311116174926, next_state=array([-0.01644936,  1.3845133 , -0.5490331 , -0.39506158,  0.01708808,\n",
       "               0.0905586 ,  0.        ,  0.        ], dtype=float32), t=2, failed=False, limit=False),\n",
       "       SARS(state=array([-0.01644936,  1.3845133 , -0.5490331 , -0.39506158,  0.01708808,\n",
       "               0.0905586 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.8300302230607428, next_state=array([-0.02206526,  1.3764567 , -0.5654184 , -0.3581188 ,  0.02087227,\n",
       "               0.07569098,  0.        ,  0.        ], dtype=float32), t=3, failed=False, limit=False),\n",
       "       SARS(state=array([-0.02206526,  1.3764567 , -0.5654184 , -0.3581188 ,  0.02087227,\n",
       "               0.07569098,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.177847403375749, next_state=array([-0.02776842,  1.367787  , -0.57635915, -0.38541755,  0.02685231,\n",
       "               0.11961178,  0.        ,  0.        ], dtype=float32), t=4, failed=False, limit=False),\n",
       "       SARS(state=array([-0.02776842,  1.367787  , -0.57635915, -0.38541755,  0.02685231,\n",
       "               0.11961178,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.3394780539891815, next_state=array([-0.03340445,  1.3585316 , -0.5679258 , -0.41143215,  0.03112938,\n",
       "               0.08554915,  0.        ,  0.        ], dtype=float32), t=5, failed=False, limit=False),\n",
       "       SARS(state=array([-0.03340445,  1.3585316 , -0.5679258 , -0.41143215,  0.03112938,\n",
       "               0.08554915,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2799178350201132, next_state=array([-0.03913717,  1.3486826 , -0.5800579 , -0.4378885 ,  0.0378334 ,\n",
       "               0.13409303,  0.        ,  0.        ], dtype=float32), t=6, failed=False, limit=False),\n",
       "       SARS(state=array([-0.03913717,  1.3486826 , -0.5800579 , -0.4378885 ,  0.0378334 ,\n",
       "               0.13409303,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.2183505050243455, next_state=array([-0.04494467,  1.3382404 , -0.5894177 , -0.4643446 ,  0.04640275,\n",
       "               0.17140296,  0.        ,  0.        ], dtype=float32), t=7, failed=False, limit=False),\n",
       "       SARS(state=array([-0.04494467,  1.3382404 , -0.5894177 , -0.4643446 ,  0.04640275,\n",
       "               0.17140296,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3420702767965893, next_state=array([-0.05081949,  1.3271856 , -0.597839  , -0.4916717 ,  0.0566633 ,\n",
       "               0.20522992,  0.        ,  0.        ], dtype=float32), t=8, failed=False, limit=False),\n",
       "       SARS(state=array([-0.05081949,  1.3271856 , -0.597839  , -0.4916717 ,  0.0566633 ,\n",
       "               0.20522992,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.793440418139794, next_state=array([-0.05662584,  1.3155385 , -0.5892509 , -0.51799303,  0.06518932,\n",
       "               0.1705362 ,  0.        ,  0.        ], dtype=float32), t=9, failed=False, limit=False),\n",
       "       SARS(state=array([-0.05662584,  1.3155385 , -0.5892509 , -0.51799303,  0.06518932,\n",
       "               0.1705362 ,  0.        ,  0.        ], dtype=float32), action=2, reward=0.3628794228634547, next_state=array([-0.06253557,  1.3042911 , -0.59929806, -0.5002633 ,  0.07343259,\n",
       "               0.1648806 ,  0.        ,  0.        ], dtype=float32), t=10, failed=False, limit=False),\n",
       "       SARS(state=array([-0.06253557,  1.3042911 , -0.59929806, -0.5002633 ,  0.07343259,\n",
       "               0.1648806 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.4722345060107203, next_state=array([-0.06853209,  1.2924471 , -0.6101452 , -0.5269511 ,  0.0838385 ,\n",
       "               0.20813711,  0.        ,  0.        ], dtype=float32), t=11, failed=False, limit=False),\n",
       "       SARS(state=array([-0.06853209,  1.2924471 , -0.6101452 , -0.5269511 ,  0.0838385 ,\n",
       "               0.20813711,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.8660714163579815, next_state=array([-0.07446547,  1.280008  , -0.60220927, -0.5533667 ,  0.09264231,\n",
       "               0.17609245,  0.        ,  0.        ], dtype=float32), t=12, failed=False, limit=False),\n",
       "       SARS(state=array([-0.07446547,  1.280008  , -0.60220927, -0.5533667 ,  0.09264231,\n",
       "               0.17609245,  0.        ,  0.        ], dtype=float32), action=2, reward=1.3361403388816029, next_state=array([-0.08050861,  1.268313  , -0.6130634 , -0.52033454,  0.10132137,\n",
       "               0.17359746,  0.        ,  0.        ], dtype=float32), t=13, failed=False, limit=False),\n",
       "       SARS(state=array([-0.08050861,  1.268313  , -0.6130634 , -0.52033454,  0.10132137,\n",
       "               0.17359746,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4346597211933272, next_state=array([-0.08655224,  1.2560189 , -0.61308604, -0.5470208 ,  0.1099989 ,\n",
       "               0.17356627,  0.        ,  0.        ], dtype=float32), t=14, failed=False, limit=False),\n",
       "       SARS(state=array([-0.08655224,  1.2560189 , -0.61308604, -0.5470208 ,  0.1099989 ,\n",
       "               0.17356627,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.425928771635398, next_state=array([-0.09259605,  1.2431257 , -0.6131108 , -0.5736929 ,  0.11867502,\n",
       "               0.17353825,  0.        ,  0.        ], dtype=float32), t=15, failed=False, limit=False),\n",
       "       SARS(state=array([-0.09259605,  1.2431257 , -0.6131108 , -0.5736929 ,  0.11867502,\n",
       "               0.17353825,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5876369820109619, next_state=array([-0.09857044,  1.2296476 , -0.604358  , -0.5995814 ,  0.12556799,\n",
       "               0.13787165,  0.        ,  0.        ], dtype=float32), t=16, failed=False, limit=False),\n",
       "       SARS(state=array([-0.09857044,  1.2296476 , -0.604358  , -0.5995814 ,  0.12556799,\n",
       "               0.13787165,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.2362731226362484, next_state=array([-0.10454502,  1.2155702 , -0.6043757 , -0.6262551 ,  0.13246062,\n",
       "               0.13786538,  0.        ,  0.        ], dtype=float32), t=17, failed=False, limit=False),\n",
       "       SARS(state=array([-0.10454502,  1.2155702 , -0.6043757 , -0.6262551 ,  0.13246062,\n",
       "               0.13786538,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0139136224046, next_state=array([-0.11058073,  1.2008708 , -0.6120643 , -0.6540878 ,  0.1409333 ,\n",
       "               0.16946892,  0.        ,  0.        ], dtype=float32), t=18, failed=False, limit=False),\n",
       "       SARS(state=array([-0.11058073,  1.2008708 , -0.6120643 , -0.6540878 ,  0.1409333 ,\n",
       "               0.16946892,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.30413809771334743, next_state=array([-0.11652527,  1.1855901 , -0.60059226, -0.6797299 ,  0.14706877,\n",
       "               0.12271991,  0.        ,  0.        ], dtype=float32), t=19, failed=False, limit=False),\n",
       "       SARS(state=array([-0.11652527,  1.1855901 , -0.60059226, -0.6797299 ,  0.14706877,\n",
       "               0.12271991,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.016705971706811623, next_state=array([-0.12237559,  1.1697387 , -0.5887257 , -0.7048871 ,  0.15076542,\n",
       "               0.07393968,  0.        ,  0.        ], dtype=float32), t=20, failed=False, limit=False),\n",
       "       SARS(state=array([-0.12237559,  1.1697387 , -0.5887257 , -0.7048871 ,  0.15076542,\n",
       "               0.07393968,  0.        ,  0.        ], dtype=float32), action=3, reward=0.009482012158600811, next_state=array([-0.12815113,  1.1533163 , -0.5792967 , -0.7300623 ,  0.15250772,\n",
       "               0.03484914,  0.        ,  0.        ], dtype=float32), t=21, failed=False, limit=False),\n",
       "       SARS(state=array([-0.12815113,  1.1533163 , -0.5792967 , -0.7300623 ,  0.15250772,\n",
       "               0.03484914,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6525323532961806, next_state=array([-0.13392667,  1.1362938 , -0.5793003 , -0.7567321 ,  0.15425006,\n",
       "               0.03484993,  0.        ,  0.        ], dtype=float32), t=22, failed=False, limit=False),\n",
       "       SARS(state=array([-0.13392667,  1.1362938 , -0.5793003 , -0.7567321 ,  0.15425006,\n",
       "               0.03484993,  0.        ,  0.        ], dtype=float32), action=3, reward=0.029865186865437182, next_state=array([-0.13963775,  1.1186795 , -0.5712148 , -0.7828625 ,  0.15435903,\n",
       "               0.00217985,  0.        ,  0.        ], dtype=float32), t=23, failed=False, limit=False),\n",
       "       SARS(state=array([-0.13963775,  1.1186795 , -0.5712148 , -0.7828625 ,  0.15435903,\n",
       "               0.00217985,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.4439176960270572, next_state=array([-0.14534874,  1.1004654 , -0.57121354, -0.80953145,  0.15446866,\n",
       "               0.00219287,  0.        ,  0.        ], dtype=float32), t=24, failed=False, limit=False),\n",
       "       SARS(state=array([-0.14534874,  1.1004654 , -0.57121354, -0.80953145,  0.15446866,\n",
       "               0.00219287,  0.        ,  0.        ], dtype=float32), action=3, reward=0.4946137362529168, next_state=array([-0.15096197,  1.0816481 , -0.55899495, -0.8360857 ,  0.15214296,\n",
       "              -0.04651409,  0.        ,  0.        ], dtype=float32), t=25, failed=False, limit=False),\n",
       "       SARS(state=array([-0.15096197,  1.0816481 , -0.55899495, -0.8360857 ,  0.15214296,\n",
       "              -0.04651409,  0.        ,  0.        ], dtype=float32), action=2, reward=1.660928076437284, next_state=array([-0.15680256,  1.0631496 , -0.5811101 , -0.8218586 ,  0.14920697,\n",
       "              -0.05871984,  0.        ,  0.        ], dtype=float32), t=26, failed=False, limit=False),\n",
       "       SARS(state=array([-0.15680256,  1.0631496 , -0.5811101 , -0.8218586 ,  0.14920697,\n",
       "              -0.05871984,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.09461562421537906, next_state=array([-0.16264305,  1.044051  , -0.5811099 , -0.84852594,  0.14627098,\n",
       "              -0.05871978,  0.        ,  0.        ], dtype=float32), t=27, failed=False, limit=False),\n",
       "       SARS(state=array([-0.16264305,  1.044051  , -0.5811099 , -0.84852594,  0.14627098,\n",
       "              -0.05871978,  0.        ,  0.        ], dtype=float32), action=3, reward=0.6306612818354449, next_state=array([-0.16841516,  1.0243698 , -0.572507  , -0.8742729 ,  0.14157985,\n",
       "              -0.09382258,  0.        ,  0.        ], dtype=float32), t=28, failed=False, limit=False),\n",
       "       SARS(state=array([-0.16841516,  1.0243698 , -0.572507  , -0.8742729 ,  0.14157985,\n",
       "              -0.09382258,  0.        ,  0.        ], dtype=float32), action=3, reward=0.6907756910772787, next_state=array([-0.1741251 ,  1.0040901 , -0.5647236 , -0.9007366 ,  0.13533494,\n",
       "              -0.12489857,  0.        ,  0.        ], dtype=float32), t=29, failed=False, limit=False),\n",
       "       SARS(state=array([-0.1741251 ,  1.0040901 , -0.5647236 , -0.9007366 ,  0.13533494,\n",
       "              -0.12489857,  0.        ,  0.        ], dtype=float32), action=3, reward=0.8815693985750113, next_state=array([-0.1797761 ,  0.9832253 , -0.5573071 , -0.9266373 ,  0.12757924,\n",
       "              -0.1551139 ,  0.        ,  0.        ], dtype=float32), t=30, failed=False, limit=False),\n",
       "       SARS(state=array([-0.1797761 ,  0.9832253 , -0.5573071 , -0.9266373 ,  0.12757924,\n",
       "              -0.1551139 ,  0.        ,  0.        ], dtype=float32), action=0, reward=0.4866754691764186, next_state=array([-0.18542719,  0.9617612 , -0.55730605, -0.9533089 ,  0.11982356,\n",
       "              -0.15511362,  0.        ,  0.        ], dtype=float32), t=31, failed=False, limit=False),\n",
       "       SARS(state=array([-0.18542719,  0.9617612 , -0.55730605, -0.9533089 ,  0.11982356,\n",
       "              -0.15511362,  0.        ,  0.        ], dtype=float32), action=0, reward=0.5195121338365425, next_state=array([-0.19107828,  0.939698  , -0.55730516, -0.9799805 ,  0.11206791,\n",
       "              -0.15511319,  0.        ,  0.        ], dtype=float32), t=32, failed=False, limit=False),\n",
       "       SARS(state=array([-0.19107828,  0.939698  , -0.55730516, -0.9799805 ,  0.11206791,\n",
       "              -0.15511319,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.059938674238678685, next_state=array([-0.19679365,  0.9170308 , -0.5653467 , -1.0069771 ,  0.10592648,\n",
       "              -0.12282856,  0.        ,  0.        ], dtype=float32), t=33, failed=False, limit=False),\n",
       "       SARS(state=array([-0.19679365,  0.9170308 , -0.5653467 , -1.0069771 ,  0.10592648,\n",
       "              -0.12282856,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.29252048829127264, next_state=array([-0.20258394,  0.89375466, -0.5747552 , -1.0341984 ,  0.1016808 ,\n",
       "              -0.08491354,  0.        ,  0.        ], dtype=float32), t=34, failed=False, limit=False),\n",
       "       SARS(state=array([-0.20258394,  0.89375466, -0.5747552 , -1.0341984 ,  0.1016808 ,\n",
       "              -0.08491354,  0.        ,  0.        ], dtype=float32), action=2, reward=3.6941590338743824, next_state=array([-0.20831856,  0.8708081 , -0.56973666, -1.0196    ,  0.09798178,\n",
       "              -0.07398031,  0.        ,  0.        ], dtype=float32), t=35, failed=False, limit=False),\n",
       "       SARS(state=array([-0.20831856,  0.8708081 , -0.56973666, -1.0196    ,  0.09798178,\n",
       "              -0.07398031,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.6540540004691298, next_state=array([-0.21414046,  0.8472496 , -0.5806828 , -1.0469482 ,  0.09648956,\n",
       "              -0.02984446,  0.        ,  0.        ], dtype=float32), t=36, failed=False, limit=False),\n",
       "       SARS(state=array([-0.21414046,  0.8472496 , -0.5806828 , -1.0469482 ,  0.09648956,\n",
       "              -0.02984446,  0.        ,  0.        ], dtype=float32), action=2, reward=4.905002025233853, next_state=array([-0.22001815,  0.8245471 , -0.58644056, -1.0089082 ,  0.09517209,\n",
       "              -0.02634906,  0.        ,  0.        ], dtype=float32), t=37, failed=False, limit=False),\n",
       "       SARS(state=array([-0.22001815,  0.8245471 , -0.58644056, -1.0089082 ,  0.09517209,\n",
       "              -0.02634906,  0.        ,  0.        ], dtype=float32), action=2, reward=3.9172698531117023, next_state=array([-0.22602168,  0.8025624 , -0.5988313 , -0.9770014 ,  0.09366038,\n",
       "              -0.03023415,  0.        ,  0.        ], dtype=float32), t=38, failed=False, limit=False),\n",
       "       SARS(state=array([-0.22602168,  0.8025624 , -0.5988313 , -0.9770014 ,  0.09366038,\n",
       "              -0.03023415,  0.        ,  0.        ], dtype=float32), action=2, reward=3.165597479801943, next_state=array([-0.23201366,  0.78094715, -0.5980061 , -0.96061134,  0.09248108,\n",
       "              -0.02358587,  0.        ,  0.        ], dtype=float32), t=39, failed=False, limit=False),\n",
       "       SARS(state=array([-0.23201366,  0.78094715, -0.5980061 , -0.96061134,  0.09248108,\n",
       "              -0.02358587,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.0454493257563502, next_state=array([-0.23808722,  0.7587165 , -0.6082564 , -0.988078  ,  0.09337375,\n",
       "               0.01785315,  0.        ,  0.        ], dtype=float32), t=40, failed=False, limit=False),\n",
       "       SARS(state=array([-0.23808722,  0.7587165 , -0.6082564 , -0.988078  ,  0.09337375,\n",
       "               0.01785315,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.3822209806209571, next_state=array([-0.2441608 ,  0.73588604, -0.60825646, -1.0147446 ,  0.09426639,\n",
       "               0.01785285,  0.        ,  0.        ], dtype=float32), t=41, failed=False, limit=False),\n",
       "       SARS(state=array([-0.2441608 ,  0.73588604, -0.60825646, -1.0147446 ,  0.09426639,\n",
       "               0.01785285,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.3072368831707297, next_state=array([-0.2503294 ,  0.7124419 , -0.62018484, -1.0421759 ,  0.09756445,\n",
       "               0.06596112,  0.        ,  0.        ], dtype=float32), t=42, failed=False, limit=False),\n",
       "       SARS(state=array([-0.2503294 ,  0.7124419 , -0.62018484, -1.0421759 ,  0.09756445,\n",
       "               0.06596112,  0.        ,  0.        ], dtype=float32), action=2, reward=0.9131564804638514, next_state=array([-0.25671506,  0.6891489 , -0.6411133 , -1.0354078 ,  0.10008825,\n",
       "               0.05047608,  0.        ,  0.        ], dtype=float32), t=43, failed=False, limit=False),\n",
       "       SARS(state=array([-0.25671506,  0.6891489 , -0.6411133 , -1.0354078 ,  0.10008825,\n",
       "               0.05047608,  0.        ,  0.        ], dtype=float32), action=2, reward=3.4148469776498134, next_state=array([-0.26321715,  0.6665744 , -0.65262187, -1.0034773 ,  0.10248175,\n",
       "               0.04786973,  0.        ,  0.        ], dtype=float32), t=44, failed=False, limit=False),\n",
       "       SARS(state=array([-0.26321715,  0.6665744 , -0.65262187, -1.0034773 ,  0.10248175,\n",
       "               0.04786973,  0.        ,  0.        ], dtype=float32), action=3, reward=0.19253617880340926, next_state=array([-0.26963848,  0.6434122 , -0.64248055, -1.0294584 ,  0.10282844,\n",
       "               0.00693377,  0.        ,  0.        ], dtype=float32), t=45, failed=False, limit=False),\n",
       "       SARS(state=array([-0.26963848,  0.6434122 , -0.64248055, -1.0294584 ,  0.10282844,\n",
       "               0.00693377,  0.        ,  0.        ], dtype=float32), action=2, reward=2.654475700633026, next_state=array([-0.27628985,  0.62087077, -0.6648064 , -1.0018146 ,  0.10250241,\n",
       "              -0.00652065,  0.        ,  0.        ], dtype=float32), t=46, failed=False, limit=False),\n",
       "       SARS(state=array([-0.27628985,  0.62087077, -0.6648064 , -1.0018146 ,  0.10250241,\n",
       "              -0.00652065,  0.        ,  0.        ], dtype=float32), action=3, reward=0.336495134835219, next_state=array([-0.28286666,  0.59773815, -0.6554609 , -1.0279638 ,  0.10029464,\n",
       "              -0.04415537,  0.        ,  0.        ], dtype=float32), t=47, failed=False, limit=False),\n",
       "       SARS(state=array([-0.28286666,  0.59773815, -0.6554609 , -1.0279638 ,  0.10029464,\n",
       "              -0.04415537,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.19231521746135627, next_state=array([-0.28944355,  0.57400566, -0.65546083, -1.0546309 ,  0.09808687,\n",
       "              -0.04415537,  0.        ,  0.        ], dtype=float32), t=48, failed=False, limit=False),\n",
       "       SARS(state=array([-0.28944355,  0.57400566, -0.65546083, -1.0546309 ,  0.09808687,\n",
       "              -0.04415537,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.19811717076683522, next_state=array([-0.29602042,  0.5496732 , -0.6554607 , -1.081298  ,  0.09587912,\n",
       "              -0.04415531,  0.        ,  0.        ], dtype=float32), t=49, failed=False, limit=False),\n",
       "       SARS(state=array([-0.29602042,  0.5496732 , -0.6554607 , -1.081298  ,  0.09587912,\n",
       "              -0.04415531,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.20938181939862943, next_state=array([-0.30259728,  0.5247408 , -0.6554607 , -1.107965  ,  0.09367135,\n",
       "              -0.04415532,  0.        ,  0.        ], dtype=float32), t=50, failed=False, limit=False),\n",
       "       SARS(state=array([-0.30259728,  0.5247408 , -0.6554607 , -1.107965  ,  0.09367135,\n",
       "              -0.04415532,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.2271272197123153, next_state=array([-0.30917415,  0.49920845, -0.65546066, -1.134632  ,  0.09146357,\n",
       "              -0.04415541,  0.        ,  0.        ], dtype=float32), t=51, failed=False, limit=False),\n",
       "       SARS(state=array([-0.30917415,  0.49920845, -0.65546066, -1.134632  ,  0.09146357,\n",
       "              -0.04415541,  0.        ,  0.        ], dtype=float32), action=3, reward=0.3346473513690864, next_state=array([-0.31568593,  0.47308674, -0.6472855 , -1.1607318 ,  0.08760587,\n",
       "              -0.07715408,  0.        ,  0.        ], dtype=float32), t=52, failed=False, limit=False),\n",
       "       SARS(state=array([-0.31568593,  0.47308674, -0.6472855 , -1.1607318 ,  0.08760587,\n",
       "              -0.07715408,  0.        ,  0.        ], dtype=float32), action=2, reward=4.005765478158264, next_state=array([-0.32242808,  0.44781554, -0.6696403 , -1.1229033 ,  0.08307732,\n",
       "              -0.09057111,  0.        ,  0.        ], dtype=float32), t=53, failed=False, limit=False),\n",
       "       SARS(state=array([-0.32242808,  0.44781554, -0.6696403 , -1.1229033 ,  0.08307732,\n",
       "              -0.09057111,  0.        ,  0.        ], dtype=float32), action=3, reward=0.593159695996236, next_state=array([-0.32908425,  0.4219527 , -0.6588551 , -1.1491004 ,  0.07638162,\n",
       "              -0.13391414,  0.        ,  0.        ], dtype=float32), t=54, failed=False, limit=False),\n",
       "       SARS(state=array([-0.32908425,  0.4219527 , -0.6588551 , -1.1491004 ,  0.07638162,\n",
       "              -0.13391414,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.89106970115776, next_state=array([-0.33583012,  0.39547792, -0.6701131 , -1.1764333 ,  0.07195314,\n",
       "              -0.08856938,  0.        ,  0.        ], dtype=float32), t=55, failed=False, limit=False),\n",
       "       SARS(state=array([-0.33583012,  0.39547792, -0.6701131 , -1.1764333 ,  0.07195314,\n",
       "              -0.08856938,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.3047434351885272, next_state=array([-0.34257603,  0.3684035 , -0.6701129 , -1.2031018 ,  0.06752469,\n",
       "              -0.08856927,  0.        ,  0.        ], dtype=float32), t=56, failed=False, limit=False),\n",
       "       SARS(state=array([-0.34257603,  0.3684035 , -0.6701129 , -1.2031018 ,  0.06752469,\n",
       "              -0.08856927,  0.        ,  0.        ], dtype=float32), action=3, reward=0.40247934925233264, next_state=array([-0.34922925,  0.34073332, -0.6584887 , -1.2294927 ,  0.06076663,\n",
       "              -0.13516119,  0.        ,  0.        ], dtype=float32), t=57, failed=False, limit=False),\n",
       "       SARS(state=array([-0.34922925,  0.34073332, -0.6584887 , -1.2294927 ,  0.06076663,\n",
       "              -0.13516119,  0.        ,  0.        ], dtype=float32), action=1, reward=-0.8410692019930923, next_state=array([-0.35594368,  0.3124534 , -0.66617495, -1.2566787 ,  0.05555697,\n",
       "              -0.10419323,  0.        ,  0.        ], dtype=float32), t=58, failed=False, limit=False),\n",
       "       SARS(state=array([-0.35594368,  0.3124534 , -0.66617495, -1.2566787 ,  0.05555697,\n",
       "              -0.10419323,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.5143671790076212, next_state=array([-0.3626581 ,  0.28357396, -0.66617477, -1.2833476 ,  0.05034731,\n",
       "              -0.10419305,  0.        ,  0.        ], dtype=float32), t=59, failed=False, limit=False),\n",
       "       SARS(state=array([-0.3626581 ,  0.28357396, -0.66617477, -1.2833476 ,  0.05034731,\n",
       "              -0.10419305,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.6477954443227532, next_state=array([-0.36937255,  0.25409475, -0.66617453, -1.3100165 ,  0.04513767,\n",
       "              -0.10419288,  0.        ,  0.        ], dtype=float32), t=60, failed=False, limit=False),\n",
       "       SARS(state=array([-0.36937255,  0.25409475, -0.66617453, -1.3100165 ,  0.04513767,\n",
       "              -0.10419288,  0.        ,  0.        ], dtype=float32), action=2, reward=4.376751174388187, next_state=array([-0.37605897,  0.22539662, -0.66368836, -1.2753297 ,  0.04024927,\n",
       "              -0.09776811,  0.        ,  0.        ], dtype=float32), t=61, failed=False, limit=False),\n",
       "       SARS(state=array([-0.37605897,  0.22539662, -0.66368836, -1.2753297 ,  0.04024927,\n",
       "              -0.09776811,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0443455869176432, next_state=array([-0.38274536,  0.19609888, -0.6636883 , -1.3019983 ,  0.03536088,\n",
       "              -0.09776796,  0.        ,  0.        ], dtype=float32), t=62, failed=False, limit=False),\n",
       "       SARS(state=array([-0.38274536,  0.19609888, -0.6636883 , -1.3019983 ,  0.03536088,\n",
       "              -0.09776796,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9577089919220316, next_state=array([-0.3895164 ,  0.1662019 , -0.67430526, -1.3286898 ,  0.03259767,\n",
       "              -0.05526402,  0.        ,  0.        ], dtype=float32), t=63, failed=False, limit=False),\n",
       "       SARS(state=array([-0.3895164 ,  0.1662019 , -0.67430526, -1.3286898 ,  0.03259767,\n",
       "              -0.05526402,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6451323785005911, next_state=array([-0.39628738,  0.13570513, -0.67430526, -1.355357  ,  0.02983447,\n",
       "              -0.05526398,  0.        ,  0.        ], dtype=float32), t=64, failed=False, limit=False),\n",
       "       SARS(state=array([-0.39628738,  0.13570513, -0.67430526, -1.355357  ,  0.02983447,\n",
       "              -0.05526398,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1100628409202205, next_state=array([-0.40296048,  0.10460716, -0.6620203 , -1.382036  ,  0.02461228,\n",
       "              -0.10444379,  0.        ,  0.        ], dtype=float32), t=65, failed=False, limit=False),\n",
       "       SARS(state=array([-0.40296048,  0.10460716, -0.6620203 , -1.382036  ,  0.02461228,\n",
       "              -0.10444379,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2515188323814914, next_state=array([-0.40955314,  0.0729101 , -0.65192896, -1.4086536 ,  0.0173693 ,\n",
       "              -0.14485969,  0.        ,  0.        ], dtype=float32), t=66, failed=False, limit=False),\n",
       "       SARS(state=array([-0.40955314,  0.0729101 , -0.65192896, -1.4086536 ,  0.0173693 ,\n",
       "              -0.14485969,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.4175396497362829, next_state=array([-0.4160822 ,  0.04062117, -0.6439456 , -1.4349865 ,  0.00852558,\n",
       "              -0.17687438,  0.        ,  0.        ], dtype=float32), t=67, failed=False, limit=False),\n",
       "       SARS(state=array([-0.4160822 ,  0.04062117, -0.6439456 , -1.4349865 ,  0.00852558,\n",
       "              -0.17687438,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.8913787648691585, next_state=array([-0.42253333,  0.00773657, -0.63417655, -1.4615089 , -0.00227488,\n",
       "              -0.21600907,  0.        ,  0.        ], dtype=float32), t=68, failed=False, limit=False),\n",
       "       SARS(state=array([-0.42253333,  0.00773657, -0.63417655, -1.4615089 , -0.00227488,\n",
       "              -0.21600907,  0.        ,  0.        ], dtype=float32), action=3, reward=5.9156894854490085, next_state=array([-0.42889762, -0.02575163, -0.62327385, -1.4884341 , -0.01525886,\n",
       "              -0.25967962,  1.        ,  0.        ], dtype=float32), t=69, failed=False, limit=False),\n",
       "       SARS(state=array([-0.42889762, -0.02575163, -0.62327385, -1.4884341 , -0.01525886,\n",
       "              -0.25967962,  1.        ,  0.        ], dtype=float32), action=0, reward=-100, next_state=array([-0.43461305, -0.04827378, -0.7779623 , -0.53366935,  0.1183714 ,\n",
       "               4.9887385 ,  1.        ,  0.        ], dtype=float32), t=70, failed=True, limit=False)],\n",
       "      maxlen=30000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88986d2",
   "metadata": {},
   "source": [
    "# Polyak Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "131ea41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2055, -0.2319,  0.2028,  ...,  0.0922, -0.2282, -0.3254],\n",
       "        [ 0.2028, -0.3522, -0.3411,  ...,  0.1852,  0.2460, -0.2618],\n",
       "        [-0.1746, -0.3408, -0.1687,  ...,  0.2524,  0.1196,  0.1263],\n",
       "        ...,\n",
       "        [-0.1459, -0.1217, -0.0412,  ..., -0.1848,  0.2856, -0.3305],\n",
       "        [ 0.1725,  0.1390, -0.0070,  ..., -0.1292,  0.0657, -0.1553],\n",
       "        [ 0.0756,  0.2674,  0.2297,  ..., -0.1144, -0.0216,  0.1884]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parameter_1 = next(policy.policy_network.named_parameters())[1]\n",
    "test_parameter_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52883c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        ...,\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parameter_2 = test_parameter_1 * 0 + 0.0128\n",
    "test_parameter_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f54a772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1862, -0.2074,  0.1838,  ...,  0.0843, -0.2041, -0.2916],\n",
       "        [ 0.1838, -0.3157, -0.3057,  ...,  0.1679,  0.2227, -0.2343],\n",
       "        [-0.1559, -0.3054, -0.1505,  ...,  0.2284,  0.1089,  0.1150],\n",
       "        ...,\n",
       "        [-0.1301, -0.1083, -0.0358,  ..., -0.1650,  0.2583, -0.2962],\n",
       "        [ 0.1565,  0.1264, -0.0050,  ..., -0.1150,  0.0604, -0.1385],\n",
       "        [ 0.0694,  0.2419,  0.2080,  ..., -0.1017, -0.0181,  0.1708]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parameter_1 * 0.9 + test_parameter_2 * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83a08ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyak_update(network_to_update, target_network, tau=0.001):\n",
    "    with torch.no_grad():\n",
    "        for to_update, target in zip(network_to_update.parameters(), target_network.parameters()):\n",
    "            to_update *= 1-tau\n",
    "            to_update += target * tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8cc28e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.1490e-01, -1.1928e-02,  4.1765e-01, -3.2731e-01,  1.8876e-01],\n",
       "        [-2.3200e-01, -4.8993e-02,  4.3404e-01,  1.4395e-01,  1.9092e-01],\n",
       "        [-1.0534e-04, -3.0931e-01, -1.4797e-01, -2.4361e-01, -1.5164e-01],\n",
       "        ...,\n",
       "        [-4.4118e-01, -1.2890e-01, -3.0154e-02, -3.3243e-01, -1.9251e-01],\n",
       "        [-1.9203e-01,  3.5193e-01,  7.4533e-02,  2.3991e-01, -8.3312e-02],\n",
       "        [-1.2111e-01,  2.6557e-01,  2.3603e-01,  7.0378e-02,  1.5150e-01]],\n",
       "       requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0685, -0.3881, -0.4062, -0.1459,  0.2815],\n",
       "        [ 0.3961, -0.4252, -0.1942,  0.4413, -0.0097],\n",
       "        [-0.2315, -0.2041, -0.0810,  0.3366, -0.2691],\n",
       "        ...,\n",
       "        [ 0.4086,  0.1911,  0.2079, -0.1103, -0.1733],\n",
       "        [ 0.1261,  0.2942,  0.1815, -0.0397,  0.1583],\n",
       "        [ 0.1458,  0.2484, -0.2127, -0.1054, -0.4002]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.1490e-01, -1.1928e-02,  4.1765e-01, -3.2731e-01,  1.8876e-01],\n",
       "        [-2.3200e-01, -4.8993e-02,  4.3404e-01,  1.4395e-01,  1.9092e-01],\n",
       "        [-1.0534e-04, -3.0931e-01, -1.4797e-01, -2.4361e-01, -1.5164e-01],\n",
       "        ...,\n",
       "        [-4.4118e-01, -1.2890e-01, -3.0154e-02, -3.3243e-01, -1.9251e-01],\n",
       "        [-1.9203e-01,  3.5193e-01,  7.4533e-02,  2.3991e-01, -8.3312e-02],\n",
       "        [-1.2111e-01,  2.6557e-01,  2.3603e-01,  7.0378e-02,  1.5150e-01]],\n",
       "       requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0731, -0.3505, -0.3238, -0.1641,  0.2722],\n",
       "        [ 0.3333, -0.3876, -0.1313,  0.4115,  0.0103],\n",
       "        [-0.2084, -0.2146, -0.0877,  0.2786, -0.2574],\n",
       "        ...,\n",
       "        [ 0.3236,  0.1591,  0.1841, -0.1326, -0.1752],\n",
       "        [ 0.0943,  0.2999,  0.1708, -0.0117,  0.1342],\n",
       "        [ 0.1191,  0.2501, -0.1678, -0.0878, -0.3450]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_network_1 = QNetwork(5, 3)\n",
    "test_network_2 = QNetwork(5, 3)\n",
    "display(list(test_network_1.parameters())[0])\n",
    "display(list(test_network_2.parameters())[0])\n",
    "polyak_update(test_network_2, test_network_1, 0.1)\n",
    "display(list(test_network_1.parameters())[0])\n",
    "display(list(test_network_2.parameters())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a6271",
   "metadata": {},
   "source": [
    "# Log Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d9242c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.01005034, 4.60517019])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.615220521841592"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.10536052, 2.30258509])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.4079456086518722"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.22314355, 1.60943791])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.8325814637483102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.51082562, 0.91629073])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.4271163556401456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.69314718, 0.69314718])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.3862943611198906"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for p in [0.99, 0.9, 0.8, 0.6, 0.5]:\n",
    "    logs = -np.log([p, 1-p])\n",
    "    display(p, logs, sum(logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e37d9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SARS(state=array([-0.42253333,  0.00773657, -0.63417655, -1.4615089 , -0.00227488,\n",
       "        -0.21600907,  0.        ,  0.        ], dtype=float32), action=3, reward=5.9156894854490085, next_state=array([-0.42889762, -0.02575163, -0.62327385, -1.4884341 , -0.01525886,\n",
       "        -0.25967962,  1.        ,  0.        ], dtype=float32), t=69, failed=False, limit=False),\n",
       " SARS(state=array([-0.08050861,  1.268313  , -0.6130634 , -0.52033454,  0.10132137,\n",
       "         0.17359746,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4346597211933272, next_state=array([-0.08655224,  1.2560189 , -0.61308604, -0.5470208 ,  0.1099989 ,\n",
       "         0.17356627,  0.        ,  0.        ], dtype=float32), t=14, failed=False, limit=False),\n",
       " SARS(state=array([-0.15680256,  1.0631496 , -0.5811101 , -0.8218586 ,  0.14920697,\n",
       "        -0.05871984,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.09461562421537906, next_state=array([-0.16264305,  1.044051  , -0.5811099 , -0.84852594,  0.14627098,\n",
       "        -0.05871978,  0.        ,  0.        ], dtype=float32), t=27, failed=False, limit=False),\n",
       " SARS(state=array([-0.27628985,  0.62087077, -0.6648064 , -1.0018146 ,  0.10250241,\n",
       "        -0.00652065,  0.        ,  0.        ], dtype=float32), action=3, reward=0.336495134835219, next_state=array([-0.28286666,  0.59773815, -0.6554609 , -1.0279638 ,  0.10029464,\n",
       "        -0.04415537,  0.        ,  0.        ], dtype=float32), t=47, failed=False, limit=False)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(replay_buffer, k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4199269",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "![Psudocode](sac_psudocode.png)\n",
    "\n",
    "Source: https://spinningup.openai.com/en/latest/algorithms/sac.html#pseudocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8998ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_min(q1, q2, states):\n",
    "    \n",
    "    def f(q):\n",
    "        state_values = q.forward(states.to(device)).detach()\n",
    "        return state_values\n",
    "        \n",
    "    return torch.minimum(*map(f, (q1, q2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ef3f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(policy, replay_buffer):\n",
    "    stats = {}\n",
    "    # Step 11\n",
    "    training_batch = random.sample(replay_buffer, k=min(len(replay_buffer), 100))\n",
    "    # Prep\n",
    "    states = torch.tensor(np.array([sars.state for sars in training_batch]), requires_grad=False).to(device)\n",
    "    actions = torch.tensor(np.array([sars.action for sars in training_batch]), requires_grad=False).to(device)\n",
    "    actions_hot = nn.functional.one_hot(actions, env.action_space.n).to(device)\n",
    "    rewards = torch.tensor(np.array([sars.reward for sars in training_batch]), requires_grad=False).to(device)\n",
    "    next_states = torch.tensor(np.array([sars.next_state for sars in training_batch]), requires_grad=False).to(device)\n",
    "    fails = torch.tensor(np.array([sars.failed for sars in training_batch]), dtype=int, requires_grad=False).to(device)\n",
    "    # Step 12\n",
    "    next_action_probs = policy.policy_network.forward(next_states.to(device)).detach()\n",
    "    assert not next_action_probs.requires_grad\n",
    "    next_states_q_min = q_min(policy.q1_target_network, policy.q2_target_network, next_states)\n",
    "    assert not next_states_q_min.requires_grad\n",
    "    next_actions_q_min = torch.sum(next_states_q_min * next_action_probs, 1)\n",
    "    assert not next_actions_q_min.requires_grad\n",
    "    next_actions_entropy = torch.sum(next_action_probs * torch.log(next_action_probs), 1)\n",
    "    assert not next_actions_entropy.requires_grad\n",
    "    y = rewards + GAMMA * (1-fails) * (next_actions_q_min - policy.alpha_dc * next_actions_entropy)\n",
    "    assert not y.requires_grad\n",
    "    # Step 13\n",
    "    for qi, q, opt in ((1, policy.q1_network, policy.q1_optimizer),\n",
    "                       (2, policy.q2_network, policy.q2_optimizer)):\n",
    "        assert not states.requires_grad\n",
    "        assert not actions_hot.requires_grad\n",
    "        q_state_action = torch.sum(q.forward(states.to(device)) * actions_hot, 1)\n",
    "        assert q_state_action.requires_grad\n",
    "        q_loss = torch.mean((q_state_action - y)**2)\n",
    "        assert q_loss.requires_grad\n",
    "        stats[f'train/q_loss_{qi}'] = q_loss.detach()\n",
    "        assert q_loss.requires_grad\n",
    "        opt.zero_grad()\n",
    "        q_loss.backward()\n",
    "        opt.step()\n",
    "    # Step 14\n",
    "    action_probs = policy.policy_network.forward(states)\n",
    "    assert action_probs.requires_grad\n",
    "    states_q_min = q_min(policy.q1_network, policy.q2_network, states)\n",
    "    assert not states_q_min.requires_grad\n",
    "    actions_q_min = torch.sum(states_q_min * action_probs, 1)\n",
    "    assert actions_q_min.requires_grad\n",
    "    actions_entropy = torch.sum(action_probs * torch.log(action_probs), 1)\n",
    "    assert actions_entropy.requires_grad\n",
    "    stats['train/entropy'] = -actions_entropy.detach().mean()\n",
    "    stats['train/entropy_percent'] = -actions_entropy.detach().mean() / log(action_probs.shape[1])\n",
    "    policy_loss = -1 * torch.mean(actions_q_min - policy.alpha_dc * actions_entropy)\n",
    "    assert policy_loss.requires_grad\n",
    "    stats['train/policy_loss'] = policy_loss.detach()\n",
    "    policy.policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy.policy_optimizer.step()\n",
    "    # Alpha Adjust\n",
    "    assert policy.alpha.requires_grad\n",
    "    assert action_probs.requires_grad\n",
    "    policy.alpha.requires_grad_(True)\n",
    "    alpha_optimizer = torch.optim.SGD([policy.alpha], lr=ALPHA_LR)\n",
    "    alpha_loss = -1 * policy.alpha * (actions_entropy.detach().mean() + ALPHA_TARGET)\n",
    "    assert alpha_loss.requires_grad\n",
    "    stats['train/alpha_loss'] = alpha_loss.detach()\n",
    "    alpha_optimizer.zero_grad()\n",
    "    alpha_loss.backward()\n",
    "    alpha_optimizer.step()\n",
    "    policy.alpha.data.clamp_(min=0)\n",
    "    stats['train/alpha'] = policy.alpha.detach()\n",
    "    # Step 15\n",
    "    polyak_update(policy.q1_target_network, policy.q1_network, tau=TAU)\n",
    "    polyak_update(policy.q2_target_network, policy.q2_network, tau=TAU)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96080451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2000/2000 [43:49<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "tb_writer = SummaryWriter()\n",
    "\n",
    "oss = env.observation_space.shape\n",
    "if len(oss) != 1:\n",
    "    raise RuntimeError(f'Unknown observation_space.shape: {oss}')\n",
    "os_len = oss[0]\n",
    "policy = Policy(os_len, env.action_space.n)\n",
    "\n",
    "replay_buffer = deque(maxlen=30_000)\n",
    "\n",
    "def action(policy, s):\n",
    "    tensor_s = torch.tensor(s).reshape((1, -1))\n",
    "    action_weights = policy.policy_network.forward(tensor_s.to(device)).reshape((-1,)).tolist()\n",
    "    action = random.choices(range(len(action_weights)), weights=action_weights)[0]\n",
    "    return action\n",
    "\n",
    "def step(initial_s, a, r, next_s, t, failed, limit):\n",
    "    replay_buffer.append(SARS(initial_s, a, r, next_s, t, failed, limit))\n",
    "\n",
    "n_episodes = 2000\n",
    "for episode in tqdm.tqdm(range(1, n_episodes+1)):\n",
    "    episode_reward = run_episode(action, step, env, policy)\n",
    "    tb_writer.add_scalar('main/episode_reward', episode_reward, episode)\n",
    "    tb_writer.add_scalar('main/replay_buffer_length', len(replay_buffer), episode)\n",
    "    tb_writer.add_scalar('main/alpha_target', ALPHA_TARGET, episode)\n",
    "    tb_writer.add_scalar('main/alpha_target_percent', ALPHA_TARGET / log(env.action_space.n), episode)\n",
    "    policy.reset_optimizers()\n",
    "    for training_iteration in range(1, 200+1):\n",
    "        stats = train(policy, replay_buffer)\n",
    "        for stat, value in stats.items():\n",
    "            tb_writer.add_scalar(stat, value, episode)\n",
    "    if episode > n_episodes / 4:\n",
    "        ALPHA_TARGET *= 0.5**(1/800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69afe679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 279\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2', render_mode='human')\n",
    "\n",
    "def render_only(initial_s, a, r, next_s, t, failed, limit):\n",
    "    pass\n",
    "\n",
    "scores = []\n",
    "for episode in range(1, 10+1):\n",
    "    scores.append(run_episode(action, render_only, env, policy))\n",
    "\n",
    "print(f'Mean score: {sum(scores) / len(scores):.0f}')\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
