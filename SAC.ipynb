{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2601a6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devjac/Code/python/learn-pytorch/.venv/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import namedtuple, deque\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf90475",
   "metadata": {},
   "outputs": [],
   "source": [
    "RENDER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f9a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA_TARGET = 0.3      # How much we value entropy / exploration, increasing this will increase exploration.\n",
    "GAMMA = 1 - 0.01        # How much we value future rewards.\n",
    "TAU = 0.01              # How much q_target is updated when polyak averaging (step 15).\n",
    "POLICY_LR = 0.001       # Policy learning rate.\n",
    "Q_LR = 0.001            # Q learning rate.\n",
    "ALPHA_LR = 0.001        # ALPHA learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf163657",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89982995",
   "metadata": {},
   "outputs": [],
   "source": [
    "SARS = namedtuple('SARS', 'state, action, reward, next_state, t, failed, limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2cd7e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=0)\n",
    "input = torch.tensor([1, 2, 3], dtype=float)\n",
    "display(input)\n",
    "output = softmax(input)\n",
    "display(output)\n",
    "sum(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ba09d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [3., 3., 3.]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652],\n",
       "        [0.3333, 0.3333, 0.3333]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5134, 0.8228, 1.6638], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "input = torch.tensor([[1, 2, 3], [1, 2, 3], [3, 3, 3]], dtype=float)\n",
    "display(input)\n",
    "output = softmax(input)\n",
    "display(output)\n",
    "sum(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e24dbb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, 1500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1500, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        nn_out = self.linear_relu_stack(x)\n",
    "        return nn.Softmax(dim=1)(nn_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        raise RuntimeError(\"Use forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357a97db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=2000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2000, out_features=1500, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1500, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_network = PolicyNetwork(4, 2)\n",
    "policy_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8763d75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c65c4c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57f14cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0328, 0.3989, 0.7453, 0.3104],\n",
       "        [0.3251, 0.7370, 0.5895, 0.1613],\n",
       "        [0.7599, 0.7150, 0.2383, 0.7809],\n",
       "        [0.0727, 0.1167, 0.2260, 0.5418],\n",
       "        [0.3726, 0.2841, 0.5720, 0.2513]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_states = torch.rand(5, 4)\n",
    "mock_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf6c7db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4977, 0.5023],\n",
       "        [0.4966, 0.5034],\n",
       "        [0.4977, 0.5023],\n",
       "        [0.5095, 0.4905],\n",
       "        [0.5037, 0.4963]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_network.forward(mock_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d287d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, 1500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1500, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        nn_out = self.linear_relu_stack(x)\n",
    "        return nn_out\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        raise RuntimeError(\"Use forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a80af706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=2000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2000, out_features=1500, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1500, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_network = QNetwork(4, 2)\n",
    "q_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e7c0e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0431, -0.1055],\n",
       "        [-0.0283, -0.1628],\n",
       "        [-0.0539, -0.1224],\n",
       "        [-0.0311, -0.0669],\n",
       "        [-0.0473, -0.1118]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_network.forward(mock_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aeb9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(action_f, step_f, env, policy, fail_at_limit=False):\n",
    "    episode_reward = 0\n",
    "    s = env.reset()\n",
    "    for t in itertools.count(start=1):\n",
    "        a = action_f(policy, s)\n",
    "        next_state, reward, failed, info = env.step(a)\n",
    "        episode_reward += reward\n",
    "        assert t <= env._max_episode_steps\n",
    "        limit = t == env._max_episode_steps\n",
    "        if limit and not fail_at_limit:\n",
    "            failed = False\n",
    "        assert fail_at_limit or not (limit and failed)\n",
    "        step_f(s, a, reward, next_state, t, failed, limit)\n",
    "        if failed or limit:\n",
    "            break\n",
    "        s = next_state\n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e867c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    def __init__(self, env_state_size, env_action_space_size):\n",
    "        self.policy_network = PolicyNetwork(env_state_size, env_action_space_size)\n",
    "        self.q1_network = QNetwork(env_state_size, env_action_space_size)\n",
    "        self.q2_network = QNetwork(env_state_size, env_action_space_size)\n",
    "        self.q1_target_network = deepcopy(self.q1_network)\n",
    "        self.q2_target_network = deepcopy(self.q2_network)\n",
    "        self.alpha = torch.tensor(ALPHA_TARGET, dtype=float, requires_grad=True)\n",
    "        self.policy_network.to(device)\n",
    "        self.q1_network.to(device)\n",
    "        self.q2_network.to(device)\n",
    "        self.q1_target_network.to(device)\n",
    "        self.q2_target_network.to(device)\n",
    "        self.alpha.to(device)\n",
    "        self.reset_optimizers()\n",
    "\n",
    "    def reset_optimizers(self):\n",
    "        self.policy_optimizer = torch.optim.SGD(self.policy_network.parameters(), lr=POLICY_LR)\n",
    "        self.q1_optimizer = torch.optim.SGD(self.q1_network.parameters(), lr=Q_LR)\n",
    "        self.q2_optimizer = torch.optim.SGD(self.q2_network.parameters(), lr=Q_LR)\n",
    "        self.alpha_optimizer = torch.optim.SGD([self.alpha], lr=ALPHA_LR)\n",
    "\n",
    "    @property\n",
    "    def alpha_dc(self):\n",
    "        \"\"\"Alpha, (D)etached and (C)lamped\"\"\"\n",
    "        return self.alpha.detach().clamp(min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "258ee690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., dtype=torch.float64, requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor(1, dtype=float, requires_grad=True)\n",
    "display(t)\n",
    "torch.optim.SGD([t], lr=ALPHA_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2ef4891",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = deque(maxlen=30_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3835dfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3d9ddd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "856e3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "oss = env.observation_space.shape\n",
    "if len(oss) != 1:\n",
    "    raise RuntimeError(f'Unknown observation_space.shape: {oss}')\n",
    "os_len = oss[0]\n",
    "policy = Policy(os_len, env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26178da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00242882,  1.4054776 , -0.24603565, -0.2418847 ,  0.00282126,\n",
       "        0.05573068,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = env.reset()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c20fffdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0024,  1.4055, -0.2460, -0.2419,  0.0028,  0.0557,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.tensor(s).reshape((1, -1))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8200ac15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2511, 0.2705, 0.2548, 0.2236]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_output = policy.policy_network.forward(s.to(device))\n",
    "policy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3eb4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_weights = policy_output.reshape((-1,)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "481df43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b78db85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = random.choices(range(len(action_weights)), weights=action_weights)[0]\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a11637db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(policy, s):\n",
    "    tensor_s = torch.tensor(s).reshape((1, -1)).to(device)\n",
    "    action_weights = policy.policy_network.forward(tensor_s).reshape((-1,)).tolist()\n",
    "    action = random.choices(range(len(action_weights)), weights=action_weights)[0]\n",
    "    return action\n",
    "\n",
    "def step(initial_s, a, r, next_s, t, failed, limit):\n",
    "    replay_buffer.append(SARS(initial_s, a, r, next_s, t, failed, limit))\n",
    "    if RENDER:\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b642f7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-532.0120235152353"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_episode(action, step, env, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9107af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e377098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([SARS(state=array([-0.00621233,  1.4203664 , -0.6292554 ,  0.4198244 ,  0.00720531,\n",
       "               0.14253572,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.36716572510167, next_state=array([-0.01251898,  1.4292246 , -0.6401851 ,  0.39361894,  0.01661271,\n",
       "               0.18816549,  0.        ,  0.        ], dtype=float32), t=1, failed=False, limit=False),\n",
       "       SARS(state=array([-0.01251898,  1.4292246 , -0.6401851 ,  0.39361894,  0.01661271,\n",
       "               0.18816549,  0.        ,  0.        ], dtype=float32), action=0, reward=-0.4159072851060728, next_state=array([-0.0188261 ,  1.4374851 , -0.64021426,  0.36699358,  0.02601443,\n",
       "               0.18805172,  0.        ,  0.        ], dtype=float32), t=2, failed=False, limit=False),\n",
       "       SARS(state=array([-0.0188261 ,  1.4374851 , -0.64021426,  0.36699358,  0.02601443,\n",
       "               0.18805172,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.6065209238964815, next_state=array([-0.02521667,  1.4451548 , -0.6506773 ,  0.34064287,  0.0375042 ,\n",
       "               0.22981688,  0.        ,  0.        ], dtype=float32), t=3, failed=False, limit=False),\n",
       "       SARS(state=array([-0.02521667,  1.4451548 , -0.6506773 ,  0.34064287,  0.0375042 ,\n",
       "               0.22981688,  0.        ,  0.        ], dtype=float32), action=2, reward=-2.691488212193934, next_state=array([-0.03158808,  1.4530988 , -0.64894354,  0.35273534,  0.04918933,\n",
       "               0.2337244 ,  0.        ,  0.        ], dtype=float32), t=4, failed=False, limit=False),\n",
       "       SARS(state=array([-0.03158808,  1.4530988 , -0.64894354,  0.35273534,  0.04918933,\n",
       "               0.2337244 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0283121177361054, next_state=array([-0.03805571,  1.460445  , -0.66099894,  0.32597148,  0.0632819 ,\n",
       "               0.28187722,  0.        ,  0.        ], dtype=float32), t=5, failed=False, limit=False),\n",
       "       SARS(state=array([-0.03805571,  1.460445  , -0.66099894,  0.32597148,  0.0632819 ,\n",
       "               0.28187722,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.025551201242051, next_state=array([-0.04459791,  1.4671962 , -0.6703045 ,  0.29928684,  0.07922479,\n",
       "               0.31888694,  0.        ,  0.        ], dtype=float32), t=6, failed=False, limit=False),\n",
       "       SARS(state=array([-0.04459791,  1.4671962 , -0.6703045 ,  0.29928684,  0.07922479,\n",
       "               0.31888694,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.2073587587880636, next_state=array([-0.05122251,  1.4739046 , -0.6782779 ,  0.2972373 ,  0.09491507,\n",
       "               0.31383488,  0.        ,  0.        ], dtype=float32), t=7, failed=False, limit=False),\n",
       "       SARS(state=array([-0.05122251,  1.4739046 , -0.6782779 ,  0.2972373 ,  0.09491507,\n",
       "               0.31383488,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.5522767966562467, next_state=array([-0.05783615,  1.4811401 , -0.67754835,  0.32047042,  0.11099584,\n",
       "               0.3216452 ,  0.        ,  0.        ], dtype=float32), t=8, failed=False, limit=False),\n",
       "       SARS(state=array([-0.05783615,  1.4811401 , -0.67754835,  0.32047042,  0.11099584,\n",
       "               0.3216452 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.129152871638541, next_state=array([-0.06464624,  1.4887799 , -0.69658244,  0.33830473,  0.12650041,\n",
       "               0.31012008,  0.        ,  0.        ], dtype=float32), t=9, failed=False, limit=False),\n",
       "       SARS(state=array([-0.06464624,  1.4887799 , -0.69658244,  0.33830473,  0.12650041,\n",
       "               0.31012008,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.0328918118401007, next_state=array([-0.07151861,  1.4958155 , -0.70434606,  0.31116116,  0.14356022,\n",
       "               0.34122723,  0.        ,  0.        ], dtype=float32), t=10, failed=False, limit=False),\n",
       "       SARS(state=array([-0.07151861,  1.4958155 , -0.70434606,  0.31116116,  0.14356022,\n",
       "               0.34122723,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3481890136621928, next_state=array([-0.07839193,  1.5022552 , -0.704393  ,  0.28447226,  0.16061614,\n",
       "               0.34115   ,  0.        ,  0.        ], dtype=float32), t=11, failed=False, limit=False),\n",
       "       SARS(state=array([-0.07839193,  1.5022552 , -0.704393  ,  0.28447226,  0.16061614,\n",
       "               0.34115   ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.453416343001065, next_state=array([-0.08534126,  1.5080925 , -0.7138042 ,  0.2572909 ,  0.1795523 ,\n",
       "               0.37875813,  0.        ,  0.        ], dtype=float32), t=12, failed=False, limit=False),\n",
       "       SARS(state=array([-0.08534126,  1.5080925 , -0.7138042 ,  0.2572909 ,  0.1795523 ,\n",
       "               0.37875813,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5824738416253286, next_state=array([-0.09221697,  1.5133562 , -0.7044681 ,  0.23180772,  0.1965513 ,\n",
       "               0.3400107 ,  0.        ,  0.        ], dtype=float32), t=13, failed=False, limit=False),\n",
       "       SARS(state=array([-0.09221697,  1.5133562 , -0.7044681 ,  0.23180772,  0.1965513 ,\n",
       "               0.3400107 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4221959744391768, next_state=array([-0.09909363,  1.5180236 , -0.7045089 ,  0.20511252,  0.2135486 ,\n",
       "               0.33997694,  0.        ,  0.        ], dtype=float32), t=14, failed=False, limit=False),\n",
       "       SARS(state=array([-0.09909363,  1.5180236 , -0.7045089 ,  0.20511252,  0.2135486 ,\n",
       "               0.33997694,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.454849509303898, next_state=array([-0.10597134,  1.5220945 , -0.7045504 ,  0.17841662,  0.23054259,\n",
       "               0.33991092,  0.        ,  0.        ], dtype=float32), t=15, failed=False, limit=False),\n",
       "       SARS(state=array([-0.10597134,  1.5220945 , -0.7045504 ,  0.17841662,  0.23054259,\n",
       "               0.33991092,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.6751656500920533, next_state=array([-0.11293001,  1.5255322 , -0.7146691 ,  0.14972216,  0.24967296,\n",
       "               0.3826427 ,  0.        ,  0.        ], dtype=float32), t=16, failed=False, limit=False),\n",
       "       SARS(state=array([-0.11293001,  1.5255322 , -0.7146691 ,  0.14972216,  0.24967296,\n",
       "               0.3826427 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-5.473670132209622, next_state=array([-0.12010269,  1.5296894 , -0.73601407,  0.18146558,  0.26884857,\n",
       "               0.38354656,  0.        ,  0.        ], dtype=float32), t=17, failed=False, limit=False),\n",
       "       SARS(state=array([-0.12010269,  1.5296894 , -0.73601407,  0.18146558,  0.26884857,\n",
       "               0.38354656,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9162924109399728, next_state=array([-0.12721777,  1.5332832 , -0.72858965,  0.1564929 ,  0.2864044 ,\n",
       "               0.35114747,  0.        ,  0.        ], dtype=float32), t=18, failed=False, limit=False),\n",
       "       SARS(state=array([-0.12721777,  1.5332832 , -0.72858965,  0.1564929 ,  0.2864044 ,\n",
       "               0.35114747,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.7935065623958892, next_state=array([-0.13441372,  1.5362589 , -0.7385738 ,  0.12840155,  0.30601808,\n",
       "               0.39230958,  0.        ,  0.        ], dtype=float32), t=19, failed=False, limit=False),\n",
       "       SARS(state=array([-0.13441372,  1.5362589 , -0.7385738 ,  0.12840155,  0.30601808,\n",
       "               0.39230958,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9010100462072319, next_state=array([-0.14154491,  1.5386748 , -0.73021656,  0.10367624,  0.3237967 ,\n",
       "               0.35560408,  0.        ,  0.        ], dtype=float32), t=20, failed=False, limit=False),\n",
       "       SARS(state=array([-0.14154491,  1.5386748 , -0.73021656,  0.10367624,  0.3237967 ,\n",
       "               0.35560408,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.7014542896433227, next_state=array([-0.14867735,  1.5404947 , -0.730251  ,  0.07697321,  0.34157348,\n",
       "               0.35556775,  0.        ,  0.        ], dtype=float32), t=21, failed=False, limit=False),\n",
       "       SARS(state=array([-0.14867735,  1.5404947 , -0.730251  ,  0.07697321,  0.34157348,\n",
       "               0.35556775,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.1496610561910345, next_state=array([-0.1559021 ,  1.5416641 , -0.74178946,  0.04726863,  0.3618984 ,\n",
       "               0.40653482,  0.        ,  0.        ], dtype=float32), t=22, failed=False, limit=False),\n",
       "       SARS(state=array([-0.1559021 ,  1.5416641 , -0.74178946,  0.04726863,  0.3618984 ,\n",
       "               0.40653482,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.0451528163305284, next_state=array([-0.16312876,  1.5422385 , -0.7418256 ,  0.0205548 ,  0.3822187 ,\n",
       "               0.40644202,  0.        ,  0.        ], dtype=float32), t=23, failed=False, limit=False),\n",
       "       SARS(state=array([-0.16312876,  1.5422385 , -0.7418256 ,  0.0205548 ,  0.3822187 ,\n",
       "               0.40644202,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.08484404818887, next_state=array([-0.17035732,  1.5422174 , -0.74185985, -0.00615969,  0.4025359 ,\n",
       "               0.4063801 ,  0.        ,  0.        ], dtype=float32), t=24, failed=False, limit=False),\n",
       "       SARS(state=array([-0.17035732,  1.5422174 , -0.74185985, -0.00615969,  0.4025359 ,\n",
       "               0.4063801 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.0480161673671364, next_state=array([-0.17751399,  1.5416194 , -0.73276746, -0.03154415,  0.42094737,\n",
       "               0.36823002,  0.        ,  0.        ], dtype=float32), t=25, failed=False, limit=False),\n",
       "       SARS(state=array([-0.17751399,  1.5416194 , -0.73276746, -0.03154415,  0.42094737,\n",
       "               0.36823002,  0.        ,  0.        ], dtype=float32), action=2, reward=-4.63717883867547, next_state=array([-0.18491611,  1.5414238 , -0.75738275, -0.01393561,  0.43958446,\n",
       "               0.37274185,  0.        ,  0.        ], dtype=float32), t=26, failed=False, limit=False),\n",
       "       SARS(state=array([-0.18491611,  1.5414238 , -0.75738275, -0.01393561,  0.43958446,\n",
       "               0.37274185,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.359079151762471, next_state=array([-0.19240484,  1.5405636 , -0.7682376 , -0.0444554 ,  0.46080717,\n",
       "               0.42445344,  0.        ,  0.        ], dtype=float32), t=27, failed=False, limit=False),\n",
       "       SARS(state=array([-0.19240484,  1.5405636 , -0.7682376 , -0.0444554 ,  0.46080717,\n",
       "               0.42445344,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.27729659367847, next_state=array([-0.19995527,  1.5390544 , -0.77589715, -0.07416001,  0.48391253,\n",
       "               0.46210736,  0.        ,  0.        ], dtype=float32), t=28, failed=False, limit=False),\n",
       "       SARS(state=array([-0.19995527,  1.5390544 , -0.77589715, -0.07416001,  0.48391253,\n",
       "               0.46210736,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.781349206909367, next_state=array([-0.20758691,  1.5368984 , -0.7858163 , -0.10398193,  0.5093281 ,\n",
       "               0.5083123 ,  0.        ,  0.        ], dtype=float32), t=29, failed=False, limit=False),\n",
       "       SARS(state=array([-0.20758691,  1.5368984 , -0.7858163 , -0.10398193,  0.5093281 ,\n",
       "               0.5083123 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.7639296797866564, next_state=array([-0.21522136,  1.5341498 , -0.78577757, -0.13069613,  0.5347426 ,\n",
       "               0.5082897 ,  0.        ,  0.        ], dtype=float32), t=30, failed=False, limit=False),\n",
       "       SARS(state=array([-0.21522136,  1.5341498 , -0.78577757, -0.13069613,  0.5347426 ,\n",
       "               0.5082897 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.140118927581709, next_state=array([-0.22293906,  1.5307436 , -0.79590535, -0.16118166,  0.56263393,\n",
       "               0.5578277 ,  0.        ,  0.        ], dtype=float32), t=31, failed=False, limit=False),\n",
       "       SARS(state=array([-0.22293906,  1.5307436 , -0.79590535, -0.16118166,  0.56263393,\n",
       "               0.5578277 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.0742788276548367, next_state=array([-0.23066053,  1.5267463 , -0.7958543 , -0.18790388,  0.59052384,\n",
       "               0.55779785,  0.        ,  0.        ], dtype=float32), t=32, failed=False, limit=False),\n",
       "       SARS(state=array([-0.23066053,  1.5267463 , -0.7958543 , -0.18790388,  0.59052384,\n",
       "               0.55779785,  0.        ,  0.        ], dtype=float32), action=2, reward=-6.297212320205506, next_state=array([-0.23875633,  1.5228527 , -0.83265716, -0.18363586,  0.61818194,\n",
       "               0.5531625 ,  0.        ,  0.        ], dtype=float32), t=33, failed=False, limit=False),\n",
       "       SARS(state=array([-0.23875633,  1.5228527 , -0.83265716, -0.18363586,  0.61818194,\n",
       "               0.5531625 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.172547177449046, next_state=array([-0.24691653,  1.518291  , -0.84045047, -0.21465738,  0.64806163,\n",
       "               0.59759414,  0.        ,  0.        ], dtype=float32), t=34, failed=False, limit=False),\n",
       "       SARS(state=array([-0.24691653,  1.518291  , -0.84045047, -0.21465738,  0.64806163,\n",
       "               0.59759414,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.3062412523783564, next_state=array([-0.2550815,  1.5131387, -0.8403841, -0.2413843,  0.6779395,\n",
       "               0.5975574,  0.       ,  0.       ], dtype=float32), t=35, failed=False, limit=False),\n",
       "       SARS(state=array([-0.2550815,  1.5131387, -0.8403841, -0.2413843,  0.6779395,\n",
       "               0.5975574,  0.       ,  0.       ], dtype=float32), action=2, reward=-6.231752460473433, next_state=array([-0.26359248,  1.5079372 , -0.87427264, -0.24396244,  0.707634  ,\n",
       "               0.59388953,  0.        ,  0.        ], dtype=float32), t=36, failed=False, limit=False),\n",
       "       SARS(state=array([-0.26359248,  1.5079372 , -0.87427264, -0.24396244,  0.707634  ,\n",
       "               0.59388953,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.1941276549942743, next_state=array([-0.27204767,  1.5022302 , -0.8663038 , -0.26579535,  0.7349238 ,\n",
       "               0.5457975 ,  0.        ,  0.        ], dtype=float32), t=37, failed=False, limit=False),\n",
       "       SARS(state=array([-0.27204767,  1.5022302 , -0.8663038 , -0.26579535,  0.7349238 ,\n",
       "               0.5457975 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.129867034935301, next_state=array([-0.28056484,  1.4958621 , -0.87353694, -0.29651976,  0.76431143,\n",
       "               0.58775365,  0.        ,  0.        ], dtype=float32), t=38, failed=False, limit=False),\n",
       "       SARS(state=array([-0.28056484,  1.4958621 , -0.87353694, -0.29651976,  0.76431143,\n",
       "               0.58775365,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.301019822047465, next_state=array([-0.2890873 ,  1.4889023 , -0.873463  , -0.32323933,  0.79369736,\n",
       "               0.5877186 ,  0.        ,  0.        ], dtype=float32), t=39, failed=False, limit=False),\n",
       "       SARS(state=array([-0.2890873 ,  1.4889023 , -0.873463  , -0.32323933,  0.79369736,\n",
       "               0.5877186 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.2381007570517384, next_state=array([-0.29755658,  1.4814347 , -0.86588573, -0.3450611 ,  0.82071006,\n",
       "               0.5402556 ,  0.        ,  0.        ], dtype=float32), t=40, failed=False, limit=False),\n",
       "       SARS(state=array([-0.29755658,  1.4814347 , -0.86588573, -0.3450611 ,  0.82071006,\n",
       "               0.5402556 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.0962446880338916, next_state=array([-0.30603066,  1.4733734 , -0.86581933, -0.37177   ,  0.8477214 ,\n",
       "               0.5402285 ,  0.        ,  0.        ], dtype=float32), t=41, failed=False, limit=False),\n",
       "       SARS(state=array([-0.30603066,  1.4733734 , -0.86581933, -0.37177   ,  0.8477214 ,\n",
       "               0.5402285 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.9295512636193437, next_state=array([-0.3145507 ,  1.4646575 , -0.8709647 , -0.40209088,  0.876445  ,\n",
       "               0.57447237,  0.        ,  0.        ], dtype=float32), t=42, failed=False, limit=False),\n",
       "       SARS(state=array([-0.3145507 ,  1.4646575 , -0.8709647 , -0.40209088,  0.876445  ,\n",
       "               0.57447237,  0.        ,  0.        ], dtype=float32), action=2, reward=-9.538984787343441, next_state=array([-0.32390365,  1.4562562 , -0.95343935, -0.38829947,  0.9048682 ,\n",
       "               0.56846344,  0.        ,  0.        ], dtype=float32), t=43, failed=False, limit=False),\n",
       "       SARS(state=array([-0.32390365,  1.4562562 , -0.95343935, -0.38829947,  0.9048682 ,\n",
       "               0.56846344,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.2010811070936143, next_state=array([-0.3332623 ,  1.4472615 , -0.95336026, -0.41500866,  0.93328977,\n",
       "               0.56843174,  0.        ,  0.        ], dtype=float32), t=44, failed=False, limit=False),\n",
       "       SARS(state=array([-0.3332623 ,  1.4472615 , -0.95336026, -0.41500866,  0.93328977,\n",
       "               0.56843174,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.407064557439951, next_state=array([-0.3426803 ,  1.437564  , -0.9602482 , -0.44809136,  0.96447456,\n",
       "               0.62369597,  0.        ,  0.        ], dtype=float32), t=45, failed=False, limit=False),\n",
       "       SARS(state=array([-0.3426803 ,  1.437564  , -0.9602482 , -0.44809136,  0.96447456,\n",
       "               0.62369597,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.648982885091782, next_state=array([-0.35215434,  1.4271625 , -0.96656626, -0.48132437,  0.99841225,\n",
       "               0.6787534 ,  0.        ,  0.        ], dtype=float32), t=46, failed=False, limit=False),\n",
       "       SARS(state=array([-0.35215434,  1.4271625 , -0.96656626, -0.48132437,  0.99841225,\n",
       "               0.6787534 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-6.837340432320718, next_state=array([-0.3620491 ,  1.4166778 , -1.0077971 , -0.48560733,  1.0326327 ,\n",
       "               0.6844095 ,  0.        ,  0.        ], dtype=float32), t=47, failed=False, limit=False),\n",
       "       SARS(state=array([-0.3620491 ,  1.4166778 , -1.0077971 , -0.48560733,  1.0326327 ,\n",
       "               0.6844095 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.773295331463771, next_state=array([-0.3719527 ,  1.405601  , -1.007672  , -0.51232564,  1.0668504 ,\n",
       "               0.68435425,  0.        ,  0.        ], dtype=float32), t=48, failed=False, limit=False),\n",
       "       SARS(state=array([-0.3719527 ,  1.405601  , -1.007672  , -0.51232564,  1.0668504 ,\n",
       "               0.68435425,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.911816202953587, next_state=array([-0.38190898,  1.393813  , -1.0132082 , -0.54602903,  1.103923  ,\n",
       "               0.7414519 ,  0.        ,  0.        ], dtype=float32), t=49, failed=False, limit=False),\n",
       "       SARS(state=array([-0.38190898,  1.393813  , -1.0132082 , -0.54602903,  1.103923  ,\n",
       "               0.7414519 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.060191355320455, next_state=array([-0.39187613,  1.3814332 , -1.0130551 , -0.5727494 ,  1.140992  ,\n",
       "               0.74138176,  0.        ,  0.        ], dtype=float32), t=50, failed=False, limit=False),\n",
       "       SARS(state=array([-0.39187613,  1.3814332 , -1.0130551 , -0.5727494 ,  1.140992  ,\n",
       "               0.74138176,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.892978680482172, next_state=array([-0.4018801,  1.3683648, -1.016346 , -0.6051472,  1.1802948,\n",
       "               0.7860552,  0.       ,  0.       ], dtype=float32), t=51, failed=False, limit=False),\n",
       "       SARS(state=array([-0.4018801,  1.3683648, -1.016346 , -0.6051472,  1.1802948,\n",
       "               0.7860552,  0.       ,  0.       ], dtype=float32), action=0, reward=-4.281571241725885, next_state=array([-0.4118967,  1.3547039, -1.0161679, -0.6318653,  1.2195933,\n",
       "               0.7859715,  0.       ,  0.       ], dtype=float32), t=52, failed=False, limit=False),\n",
       "       SARS(state=array([-0.4118967,  1.3547039, -1.0161679, -0.6318653,  1.2195933,\n",
       "               0.7859715,  0.       ,  0.       ], dtype=float32), action=3, reward=-3.448211054276014, next_state=array([-0.4219026 ,  1.3405602 , -1.0128251 , -0.65205646,  1.2563584 ,\n",
       "               0.735301  ,  0.        ,  0.        ], dtype=float32), t=53, failed=False, limit=False),\n",
       "       SARS(state=array([-0.4219026 ,  1.3405602 , -1.0128251 , -0.65205646,  1.2563584 ,\n",
       "               0.735301  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.030900458439305, next_state=array([-0.43191996,  1.3258221 , -1.0126643 , -0.6787601 ,  1.29312   ,\n",
       "               0.73523253,  0.        ,  0.        ], dtype=float32), t=54, failed=False, limit=False),\n",
       "       SARS(state=array([-0.43191996,  1.3258221 , -1.0126643 , -0.6787601 ,  1.29312   ,\n",
       "               0.73523253,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.029080805099227, next_state=array([-0.4419488,  1.3104888, -1.0125017, -0.7054597,  1.3298782,\n",
       "               0.7351641,  0.       ,  0.       ], dtype=float32), t=55, failed=False, limit=False),\n",
       "       SARS(state=array([-0.4419488,  1.3104888, -1.0125017, -0.7054597,  1.3298782,\n",
       "               0.7351641,  0.       ,  0.       ], dtype=float32), action=2, reward=-11.351810293324423, next_state=array([-0.4529497,  1.2949574, -1.1084079, -0.7145721,  1.3667628,\n",
       "               0.73769  ,  0.       ,  0.       ], dtype=float32), t=56, failed=False, limit=False),\n",
       "       SARS(state=array([-0.4529497,  1.2949574, -1.1084079, -0.7145721,  1.3667628,\n",
       "               0.73769  ,  0.       ,  0.       ], dtype=float32), action=0, reward=-3.989707301830947, next_state=array([-0.46396255,  1.2788293 , -1.1082408 , -0.7412639 ,  1.4036438 ,\n",
       "               0.73762095,  0.        ,  0.        ], dtype=float32), t=57, failed=False, limit=False),\n",
       "       SARS(state=array([-0.46396255,  1.2788293 , -1.1082408 , -0.7412639 ,  1.4036438 ,\n",
       "               0.73762095,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.989284174120712, next_state=array([-0.4749872 ,  1.2621045 , -1.1080726 , -0.76795155,  1.4405215 ,\n",
       "               0.73755187,  0.        ,  0.        ], dtype=float32), t=58, failed=False, limit=False),\n",
       "       SARS(state=array([-0.4749872 ,  1.2621045 , -1.1080726 , -0.76795155,  1.4405215 ,\n",
       "               0.73755187,  0.        ,  0.        ], dtype=float32), action=2, reward=-8.02758401746313, next_state=array([-0.48645338,  1.2446574 , -1.1507996 , -0.7997366 ,  1.4767568 ,\n",
       "               0.7247066 ,  0.        ,  0.        ], dtype=float32), t=59, failed=False, limit=False),\n",
       "       SARS(state=array([-0.48645338,  1.2446574 , -1.1507996 , -0.7997366 ,  1.4767568 ,\n",
       "               0.7247066 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.620294473777306, next_state=array([-0.4979362 ,  1.2264988 , -1.1512873 , -0.83317095,  1.5155392 ,\n",
       "               0.77564657,  0.        ,  0.        ], dtype=float32), t=60, failed=False, limit=False),\n",
       "       SARS(state=array([-0.4979362 ,  1.2264988 , -1.1512873 , -0.83317095,  1.5155392 ,\n",
       "               0.77564657,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.4688561436017538, next_state=array([-0.5094303,  1.2078617, -1.1508362, -0.8526563,  1.5516052,\n",
       "               0.7213222,  0.       ,  0.       ], dtype=float32), t=61, failed=False, limit=False),\n",
       "       SARS(state=array([-0.5094303,  1.2078617, -1.1508362, -0.8526563,  1.5516052,\n",
       "               0.7213222,  0.       ,  0.       ], dtype=float32), action=2, reward=-11.339813079451051, next_state=array([-0.52186304,  1.1887916 , -1.2433807 , -0.87220377,  1.5880992 ,\n",
       "               0.72988063,  0.        ,  0.        ], dtype=float32), t=62, failed=False, limit=False),\n",
       "       SARS(state=array([-0.52186304,  1.1887916 , -1.2433807 , -0.87220377,  1.5880992 ,\n",
       "               0.72988063,  0.        ,  0.        ], dtype=float32), action=2, reward=-10.235946108977704, next_state=array([-0.5349935 ,  1.1689254 , -1.3118327 , -0.90720534,  1.6240405 ,\n",
       "               0.71882594,  0.        ,  0.        ], dtype=float32), t=63, failed=False, limit=False),\n",
       "       SARS(state=array([-0.5349935 ,  1.1689254 , -1.3118327 , -0.90720534,  1.6240405 ,\n",
       "               0.71882594,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.474195418895845, next_state=array([-0.5481361 ,  1.1483438 , -1.3115097 , -0.94068265,  1.6625482 ,\n",
       "               0.7701534 ,  0.        ,  0.        ], dtype=float32), t=64, failed=False, limit=False),\n",
       "       SARS(state=array([-0.5481361 ,  1.1483438 , -1.3115097 , -0.94068265,  1.6625482 ,\n",
       "               0.7701534 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-9.271067724395653, next_state=array([-0.5618095,  1.126851 , -1.3631885, -0.9805966,  1.7003214,\n",
       "               0.7554661,  0.       ,  0.       ], dtype=float32), t=65, failed=False, limit=False),\n",
       "       SARS(state=array([-0.5618095,  1.126851 , -1.3631885, -0.9805966,  1.7003214,\n",
       "               0.7554661,  0.       ,  0.       ], dtype=float32), action=2, reward=-9.977245467097863, next_state=array([-0.5760881,  1.1043677, -1.4224036, -1.0239327,  1.7372589,\n",
       "               0.7387505,  0.       ,  0.       ], dtype=float32), t=66, failed=False, limit=False),\n",
       "       SARS(state=array([-0.5760881,  1.1043677, -1.4224036, -1.0239327,  1.7372589,\n",
       "               0.7387505,  0.       ,  0.       ], dtype=float32), action=0, reward=-3.8861141612612187, next_state=array([-0.59037846,  1.0812817 , -1.4222335 , -1.0505824 ,  1.7741929 ,\n",
       "               0.738681  ,  0.        ,  0.        ], dtype=float32), t=67, failed=False, limit=False),\n",
       "       SARS(state=array([-0.59037846,  1.0812817 , -1.4222335 , -1.0505824 ,  1.7741929 ,\n",
       "               0.738681  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.400862002696527, next_state=array([-0.60465825,  1.0574715 , -1.4191557 , -1.0843755 ,  1.8138826 ,\n",
       "               0.7937938 ,  0.        ,  0.        ], dtype=float32), t=68, failed=False, limit=False),\n",
       "       SARS(state=array([-0.60465825,  1.0574715 , -1.4191557 , -1.0843755 ,  1.8138826 ,\n",
       "               0.7937938 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-10.871794146519324, next_state=array([-0.6195979 ,  1.0325553 , -1.4838108 , -1.1327758 ,  1.8527876 ,\n",
       "               0.77810144,  0.        ,  0.        ], dtype=float32), t=69, failed=False, limit=False),\n",
       "       SARS(state=array([-0.6195979 ,  1.0325553 , -1.4838108 , -1.1327758 ,  1.8527876 ,\n",
       "               0.77810144,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.112874403207343, next_state=array([-0.6345504 ,  1.0070336 , -1.4836266 , -1.1594094 ,  1.8916886 ,\n",
       "               0.77802044,  0.        ,  0.        ], dtype=float32), t=70, failed=False, limit=False),\n",
       "       SARS(state=array([-0.6345504 ,  1.0070336 , -1.4836266 , -1.1594094 ,  1.8916886 ,\n",
       "               0.77802044,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.144013945987751, next_state=array([-0.6495156,  0.9809053, -1.4834445, -1.1860383,  1.9305855,\n",
       "               0.7779392,  0.       ,  0.       ], dtype=float32), t=71, failed=False, limit=False),\n",
       "       SARS(state=array([-0.6495156,  0.9809053, -1.4834445, -1.1860383,  1.9305855,\n",
       "               0.7779392,  0.       ,  0.       ], dtype=float32), action=0, reward=-4.1789128531133315, next_state=array([-0.6644934 ,  0.95416975, -1.4832646 , -1.2126622 ,  1.9694784 ,\n",
       "               0.77785814,  0.        ,  0.        ], dtype=float32), t=72, failed=False, limit=False),\n",
       "       SARS(state=array([-0.6644934 ,  0.95416975, -1.4832646 , -1.2126622 ,  1.9694784 ,\n",
       "               0.77785814,  0.        ,  0.        ], dtype=float32), action=2, reward=-13.641392095068273, next_state=array([-0.6804287 ,  0.9261791 , -1.5776691 , -1.2679669 ,  2.008224  ,\n",
       "               0.77491343,  0.        ,  0.        ], dtype=float32), t=73, failed=False, limit=False),\n",
       "       SARS(state=array([-0.6804287 ,  0.9261791 , -1.5776691 , -1.2679669 ,  2.008224  ,\n",
       "               0.77491343,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.217092653164059, next_state=array([-0.6963761,  0.89758  , -1.577496 , -1.2945822,  2.0469656,\n",
       "               0.7748334,  0.       ,  0.       ], dtype=float32), t=74, failed=False, limit=False),\n",
       "       SARS(state=array([-0.6963761,  0.89758  , -1.577496 , -1.2945822,  2.0469656,\n",
       "               0.7748334,  0.       ,  0.       ], dtype=float32), action=2, reward=-9.314957947473477, next_state=array([-0.71288234,  0.86822003, -1.6316662 , -1.3283582 ,  2.0864477 ,\n",
       "               0.78964174,  0.        ,  0.        ], dtype=float32), t=75, failed=False, limit=False),\n",
       "       SARS(state=array([-0.71288234,  0.86822003, -1.6316662 , -1.3283582 ,  2.0864477 ,\n",
       "               0.78964174,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.40159499940421, next_state=array([-0.7294006,  0.83825  , -1.6314933, -1.3549625,  2.1259255,\n",
       "               0.789557 ,  0.       ,  0.       ], dtype=float32), t=76, failed=False, limit=False),\n",
       "       SARS(state=array([-0.7294006,  0.83825  , -1.6314933, -1.3549625,  2.1259255,\n",
       "               0.789557 ,  0.       ,  0.       ], dtype=float32), action=1, reward=-4.7148713285540955, next_state=array([-0.7458986 ,  0.80757684, -1.6269033 , -1.386871  ,  2.1675692 ,\n",
       "               0.8328705 ,  0.        ,  0.        ], dtype=float32), t=77, failed=False, limit=False),\n",
       "       SARS(state=array([-0.7458986 ,  0.80757684, -1.6269033 , -1.386871  ,  2.1675692 ,\n",
       "               0.8328705 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.673321099398236, next_state=array([-0.7624582 ,  0.7763848 , -1.6330645 , -1.4079491 ,  2.2067735 ,\n",
       "               0.78409356,  0.        ,  0.        ], dtype=float32), t=78, failed=False, limit=False),\n",
       "       SARS(state=array([-0.7624582 ,  0.7763848 , -1.6330645 , -1.4079491 ,  2.2067735 ,\n",
       "               0.78409356,  0.        ,  0.        ], dtype=float32), action=2, reward=-9.79942005450248, next_state=array([-0.77944875,  0.7439717 , -1.675134  , -1.461408  ,  2.2456176 ,\n",
       "               0.7768843 ,  0.        ,  0.        ], dtype=float32), t=79, failed=False, limit=False),\n",
       "       SARS(state=array([-0.77944875,  0.7439717 , -1.675134  , -1.461408  ,  2.2456176 ,\n",
       "               0.7768843 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.638695470269113, next_state=array([-0.7964497,  0.710946 , -1.674983 , -1.4879972,  2.284458 ,\n",
       "               0.7768036,  0.       ,  0.       ], dtype=float32), t=80, failed=False, limit=False),\n",
       "       SARS(state=array([-0.7964497,  0.710946 , -1.674983 , -1.4879972,  2.284458 ,\n",
       "               0.7768036,  0.       ,  0.       ], dtype=float32), action=2, reward=-11.954590963452848, next_state=array([-0.81399345,  0.6762833 , -1.7286413 , -1.5597106 ,  2.32252   ,\n",
       "               0.7612403 ,  0.        ,  0.        ], dtype=float32), t=81, failed=False, limit=False),\n",
       "       SARS(state=array([-0.81399345,  0.6762833 , -1.7286413 , -1.5597106 ,  2.32252   ,\n",
       "               0.7612403 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.718457722036788, next_state=array([-0.8315951 ,  0.6410922 , -1.7349465 , -1.5814708 ,  2.3583665 ,\n",
       "               0.71692824,  0.        ,  0.        ], dtype=float32), t=82, failed=False, limit=False),\n",
       "       SARS(state=array([-0.8315951 ,  0.6410922 , -1.7349465 , -1.5814708 ,  2.3583665 ,\n",
       "               0.71692824,  0.        ,  0.        ], dtype=float32), action=0, reward=-4.6573082597614075, next_state=array([-0.84920484,  0.6052888 , -1.7348299 , -1.6080621 ,  2.3942096 ,\n",
       "               0.71686476,  0.        ,  0.        ], dtype=float32), t=83, failed=False, limit=False),\n",
       "       SARS(state=array([-0.84920484,  0.6052888 , -1.7348299 , -1.6080621 ,  2.3942096 ,\n",
       "               0.71686476,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.803585718680693, next_state=array([-0.8668891 ,  0.56897414, -1.7435156 , -1.6289234 ,  2.427287  ,\n",
       "               0.661551  ,  0.        ,  0.        ], dtype=float32), t=84, failed=False, limit=False),\n",
       "       SARS(state=array([-0.8668891 ,  0.56897414, -1.7435156 , -1.6289234 ,  2.427287  ,\n",
       "               0.661551  ,  0.        ,  0.        ], dtype=float32), action=2, reward=-12.845988609427696, next_state=array([-0.88528687,  0.5311704 , -1.8135931 , -1.6948419 ,  2.4610589 ,\n",
       "               0.67543495,  0.        ,  0.        ], dtype=float32), t=85, failed=False, limit=False),\n",
       "       SARS(state=array([-0.88528687,  0.5311704 , -1.8135931 , -1.6948419 ,  2.4610589 ,\n",
       "               0.67543495,  0.        ,  0.        ], dtype=float32), action=3, reward=-4.92589798687382, next_state=array([-0.9037501 ,  0.49284068, -1.8213043 , -1.7166619 ,  2.4924788 ,\n",
       "               0.6283976 ,  0.        ,  0.        ], dtype=float32), t=86, failed=False, limit=False),\n",
       "       SARS(state=array([-0.9037501 ,  0.49284068, -1.8213043 , -1.7166619 ,  2.4924788 ,\n",
       "               0.6283976 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.766854648900817, next_state=array([-0.9221711 ,  0.45384866, -1.8151181 , -1.7462105 ,  2.525544  ,\n",
       "               0.661302  ,  0.        ,  0.        ], dtype=float32), t=87, failed=False, limit=False),\n",
       "       SARS(state=array([-0.9221711 ,  0.45384866, -1.8151181 , -1.7462105 ,  2.525544  ,\n",
       "               0.661302  ,  0.        ,  0.        ], dtype=float32), action=0, reward=-5.148594489076004, next_state=array([-0.9405977 ,  0.4142449 , -1.8150364 , -1.7728026 ,  2.5586066 ,\n",
       "               0.66125196,  0.        ,  0.        ], dtype=float32), t=88, failed=False, limit=False),\n",
       "       SARS(state=array([-0.9405977 ,  0.4142449 , -1.8150364 , -1.7728026 ,  2.5586066 ,\n",
       "               0.66125196,  0.        ,  0.        ], dtype=float32), action=2, reward=-12.052105325704066, next_state=array([-0.95938766,  0.37276992, -1.8514162 , -1.855079  ,  2.5909123 ,\n",
       "               0.6461136 ,  0.        ,  0.        ], dtype=float32), t=89, failed=False, limit=False),\n",
       "       SARS(state=array([-0.95938766,  0.37276992, -1.8514162 , -1.855079  ,  2.5909123 ,\n",
       "               0.6461136 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-12.704562570869872, next_state=array([-0.9785686,  0.329327 , -1.8905493, -1.9417155,  2.6225498,\n",
       "               0.6327504,  0.       ,  0.       ], dtype=float32), t=90, failed=False, limit=False),\n",
       "       SARS(state=array([-0.9785686,  0.329327 , -1.8905493, -1.9417155,  2.6225498,\n",
       "               0.6327504,  0.       ,  0.       ], dtype=float32), action=0, reward=-5.594437734811663, next_state=array([-0.997754  ,  0.28527254, -1.8904848 , -1.9683096 ,  2.654185  ,\n",
       "               0.6327069 ,  0.        ,  0.        ], dtype=float32), t=91, failed=False, limit=False),\n",
       "       SARS(state=array([-0.997754  ,  0.28527254, -1.8904848 , -1.9683096 ,  2.654185  ,\n",
       "               0.6327069 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-100, next_state=array([-1.0169435 ,  0.24060632, -1.8904238 , -1.9949024 ,  2.6858182 ,\n",
       "               0.63266325,  0.        ,  0.        ], dtype=float32), t=92, failed=True, limit=False)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88986d2",
   "metadata": {},
   "source": [
    "# Polyak Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "131ea41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1246, -0.1029,  0.2727,  ..., -0.0717, -0.1187,  0.0831],\n",
       "        [-0.1792, -0.1695,  0.0921,  ..., -0.3296,  0.0166, -0.2935],\n",
       "        [ 0.1052, -0.1717, -0.0611,  ...,  0.1389,  0.3051, -0.1386],\n",
       "        ...,\n",
       "        [-0.1268,  0.3387, -0.1519,  ..., -0.2215,  0.3334,  0.2127],\n",
       "        [ 0.1328, -0.0655,  0.2023,  ..., -0.2123, -0.2214, -0.2885],\n",
       "        [-0.3128,  0.3353, -0.2610,  ...,  0.1156, -0.2113,  0.0482]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parameter_1 = next(policy.policy_network.named_parameters())[1]\n",
    "test_parameter_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52883c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        ...,\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parameter_2 = test_parameter_1 * 0 + 0.0128\n",
    "test_parameter_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f54a772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1134, -0.0913,  0.2467,  ..., -0.0633, -0.1055,  0.0761],\n",
       "        [-0.1600, -0.1513,  0.0841,  ..., -0.2954,  0.0162, -0.2629],\n",
       "        [ 0.0960, -0.1532, -0.0537,  ...,  0.1263,  0.2759, -0.1234],\n",
       "        ...,\n",
       "        [-0.1129,  0.3061, -0.1355,  ..., -0.1981,  0.3013,  0.1927],\n",
       "        [ 0.1208, -0.0576,  0.1834,  ..., -0.1898, -0.1980, -0.2584],\n",
       "        [-0.2803,  0.3031, -0.2337,  ...,  0.1053, -0.1889,  0.0447]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parameter_1 * 0.9 + test_parameter_2 * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83a08ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyak_update(network_to_update, target_network, tau=0.001):\n",
    "    with torch.no_grad():\n",
    "        for to_update, target in zip(network_to_update.parameters(), target_network.parameters()):\n",
    "            to_update *= 1-tau\n",
    "            to_update += target * tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8cc28e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1269, -0.4354,  0.0163, -0.1715, -0.3544],\n",
       "        [ 0.3526, -0.1543,  0.0717,  0.2197,  0.1529],\n",
       "        [-0.0542, -0.0805, -0.0672,  0.3208,  0.3937],\n",
       "        ...,\n",
       "        [ 0.3285, -0.0311,  0.0709, -0.3532, -0.2510],\n",
       "        [-0.0835,  0.2199, -0.2628, -0.2567,  0.1461],\n",
       "        [ 0.1652,  0.2135, -0.2146, -0.0699, -0.1571]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4314, -0.0635, -0.1606, -0.0519, -0.0437],\n",
       "        [ 0.1235,  0.4140,  0.0686,  0.3580, -0.3923],\n",
       "        [-0.4411,  0.0470, -0.2552,  0.3637,  0.2513],\n",
       "        ...,\n",
       "        [ 0.4167, -0.2589, -0.3410,  0.2700, -0.4023],\n",
       "        [-0.2164,  0.0037, -0.3848,  0.1103, -0.0099],\n",
       "        [ 0.2880,  0.0448, -0.0536,  0.2964,  0.1785]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1269, -0.4354,  0.0163, -0.1715, -0.3544],\n",
       "        [ 0.3526, -0.1543,  0.0717,  0.2197,  0.1529],\n",
       "        [-0.0542, -0.0805, -0.0672,  0.3208,  0.3937],\n",
       "        ...,\n",
       "        [ 0.3285, -0.0311,  0.0709, -0.3532, -0.2510],\n",
       "        [-0.0835,  0.2199, -0.2628, -0.2567,  0.1461],\n",
       "        [ 0.1652,  0.2135, -0.2146, -0.0699, -0.1571]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3755, -0.1007, -0.1429, -0.0639, -0.0748],\n",
       "        [ 0.1464,  0.3572,  0.0689,  0.3442, -0.3378],\n",
       "        [-0.4024,  0.0343, -0.2364,  0.3594,  0.2655],\n",
       "        ...,\n",
       "        [ 0.4079, -0.2362, -0.2998,  0.2077, -0.3872],\n",
       "        [-0.2031,  0.0253, -0.3726,  0.0736,  0.0057],\n",
       "        [ 0.2758,  0.0617, -0.0697,  0.2597,  0.1449]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_network_1 = QNetwork(5, 3)\n",
    "test_network_2 = QNetwork(5, 3)\n",
    "display(list(test_network_1.parameters())[0])\n",
    "display(list(test_network_2.parameters())[0])\n",
    "polyak_update(test_network_2, test_network_1, 0.1)\n",
    "display(list(test_network_1.parameters())[0])\n",
    "display(list(test_network_2.parameters())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a6271",
   "metadata": {},
   "source": [
    "# Log Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d9242c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.01005034, 4.60517019])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.615220521841592"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.10536052, 2.30258509])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.4079456086518722"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.22314355, 1.60943791])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.8325814637483102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.51082562, 0.91629073])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.4271163556401456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.69314718, 0.69314718])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.3862943611198906"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for p in [0.99, 0.9, 0.8, 0.6, 0.5]:\n",
    "    logs = -np.log([p, 1-p])\n",
    "    display(p, logs, sum(logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e37d9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SARS(state=array([-0.95938766,  0.37276992, -1.8514162 , -1.855079  ,  2.5909123 ,\n",
       "         0.6461136 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-12.704562570869872, next_state=array([-0.9785686,  0.329327 , -1.8905493, -1.9417155,  2.6225498,\n",
       "         0.6327504,  0.       ,  0.       ], dtype=float32), t=90, failed=False, limit=False),\n",
       " SARS(state=array([-0.23066053,  1.5267463 , -0.7958543 , -0.18790388,  0.59052384,\n",
       "         0.55779785,  0.        ,  0.        ], dtype=float32), action=2, reward=-6.297212320205506, next_state=array([-0.23875633,  1.5228527 , -0.83265716, -0.18363586,  0.61818194,\n",
       "         0.5531625 ,  0.        ,  0.        ], dtype=float32), t=33, failed=False, limit=False),\n",
       " SARS(state=array([-0.32390365,  1.4562562 , -0.95343935, -0.38829947,  0.9048682 ,\n",
       "         0.56846344,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.2010811070936143, next_state=array([-0.3332623 ,  1.4472615 , -0.95336026, -0.41500866,  0.93328977,\n",
       "         0.56843174,  0.        ,  0.        ], dtype=float32), t=44, failed=False, limit=False),\n",
       " SARS(state=array([-0.3332623 ,  1.4472615 , -0.95336026, -0.41500866,  0.93328977,\n",
       "         0.56843174,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.407064557439951, next_state=array([-0.3426803 ,  1.437564  , -0.9602482 , -0.44809136,  0.96447456,\n",
       "         0.62369597,  0.        ,  0.        ], dtype=float32), t=45, failed=False, limit=False)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(replay_buffer, k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4199269",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "![Psudocode](sac_psudocode.png)\n",
    "\n",
    "Source: https://spinningup.openai.com/en/latest/algorithms/sac.html#pseudocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8998ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_min(q1, q2, states):\n",
    "    \n",
    "    def f(q):\n",
    "        state_values = q.forward(states.to(device)).detach()\n",
    "        return state_values\n",
    "        \n",
    "    return torch.minimum(*map(f, (q1, q2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ef3f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(policy, replay_buffer):\n",
    "    stats = {}\n",
    "    # Step 11\n",
    "    training_batch = random.sample(replay_buffer, k=min(len(replay_buffer), 100))\n",
    "    # Prep\n",
    "    states = torch.tensor(np.array([sars.state for sars in training_batch]), requires_grad=False).to(device)\n",
    "    actions = torch.tensor(np.array([sars.action for sars in training_batch]), requires_grad=False).to(device)\n",
    "    actions_hot = nn.functional.one_hot(actions, env.action_space.n).to(device)\n",
    "    rewards = torch.tensor(np.array([sars.reward for sars in training_batch]), requires_grad=False).to(device)\n",
    "    next_states = torch.tensor(np.array([sars.next_state for sars in training_batch]), requires_grad=False).to(device)\n",
    "    fails = torch.tensor(np.array([sars.failed for sars in training_batch]), dtype=int, requires_grad=False).to(device)\n",
    "    # Step 12\n",
    "    next_action_probs = policy.policy_network.forward(next_states.to(device)).detach()\n",
    "    assert not next_action_probs.requires_grad\n",
    "    next_states_q_min = q_min(policy.q1_target_network, policy.q2_target_network, next_states)\n",
    "    assert not next_states_q_min.requires_grad\n",
    "    next_actions_q_min = torch.sum(next_states_q_min * next_action_probs, 1)\n",
    "    assert not next_actions_q_min.requires_grad\n",
    "    next_actions_entropy = torch.sum(next_action_probs * torch.log(next_action_probs), 1)\n",
    "    assert not next_actions_entropy.requires_grad\n",
    "    y = rewards + GAMMA * (1-fails) * (next_actions_q_min - policy.alpha_dc * next_actions_entropy)\n",
    "    assert not y.requires_grad\n",
    "    # Step 13\n",
    "    for qi, q, opt in ((1, policy.q1_network, policy.q1_optimizer),\n",
    "                       (2, policy.q2_network, policy.q2_optimizer)):\n",
    "        assert not states.requires_grad\n",
    "        assert not actions_hot.requires_grad\n",
    "        q_state_action = torch.sum(q.forward(states.to(device)) * actions_hot, 1)\n",
    "        assert q_state_action.requires_grad\n",
    "        q_loss = torch.mean((q_state_action - y)**2)\n",
    "        assert q_loss.requires_grad\n",
    "        stats[f'train/q_loss_{qi}'] = q_loss.detach()\n",
    "        assert q_loss.requires_grad\n",
    "        opt.zero_grad()\n",
    "        q_loss.backward()\n",
    "        opt.step()\n",
    "    # Step 14\n",
    "    action_probs = policy.policy_network.forward(states)\n",
    "    assert action_probs.requires_grad\n",
    "    states_q_min = q_min(policy.q1_network, policy.q2_network, states)\n",
    "    assert not states_q_min.requires_grad\n",
    "    actions_q_min = torch.sum(states_q_min * action_probs, 1)\n",
    "    assert actions_q_min.requires_grad\n",
    "    actions_entropy = torch.sum(action_probs * torch.log(action_probs), 1)\n",
    "    assert actions_entropy.requires_grad\n",
    "    policy_loss = -1 * torch.mean(actions_q_min - policy.alpha_dc * actions_entropy)\n",
    "    assert policy_loss.requires_grad\n",
    "    stats['train/policy_loss'] = policy_loss.detach()\n",
    "    policy.policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy.policy_optimizer.step()\n",
    "    # Alpha Adjust\n",
    "    assert policy.alpha.requires_grad\n",
    "    assert action_probs.requires_grad\n",
    "    expected_action_log_probs = torch.log(action_probs.detach()) * action_probs.detach()\n",
    "    assert not expected_action_log_probs.requires_grad\n",
    "    alpha_loss = torch.mean(-1 * policy.alpha * (expected_action_log_probs + ALPHA_TARGET))\n",
    "    assert alpha_loss.requires_grad\n",
    "    stats['train/alpha_loss'] = alpha_loss.detach()\n",
    "    policy.alpha_optimizer.zero_grad()\n",
    "    alpha_loss.backward()\n",
    "    policy.alpha_optimizer.step()\n",
    "    stats['train/alpha'] = policy.alpha.detach()\n",
    "    # Step 15\n",
    "    polyak_update(policy.q1_target_network, policy.q1_network, tau=TAU)\n",
    "    polyak_update(policy.q2_target_network, policy.q2_network, tau=TAU)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96080451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3000/3000 [46:54<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "tb_writer = SummaryWriter()\n",
    "\n",
    "oss = env.observation_space.shape\n",
    "if len(oss) != 1:\n",
    "    raise RuntimeError(f'Unknown observation_space.shape: {oss}')\n",
    "os_len = oss[0]\n",
    "policy = Policy(os_len, env.action_space.n)\n",
    "\n",
    "replay_buffer = deque(maxlen=30_000)\n",
    "\n",
    "def action(policy, s):\n",
    "    tensor_s = torch.tensor(s).reshape((1, -1))\n",
    "    action_weights = policy.policy_network.forward(tensor_s.to(device)).reshape((-1,)).tolist()\n",
    "    action = random.choices(range(len(action_weights)), weights=action_weights)[0]\n",
    "    return action\n",
    "\n",
    "def step(initial_s, a, r, next_s, t, failed, limit):\n",
    "    replay_buffer.append(SARS(initial_s, a, r, next_s, t, failed, limit))\n",
    "    if RENDER:\n",
    "        env.render()\n",
    "\n",
    "for episode in tqdm.tqdm(range(1, 3000+1)):\n",
    "    episode_reward = run_episode(action, step, env, policy, fail_at_limit=True)\n",
    "    tb_writer.add_scalar('main/episode_reward', episode_reward, episode)\n",
    "    tb_writer.add_scalar('main/replay_buffer_length', len(replay_buffer), episode)\n",
    "    tb_writer.add_scalar('main/alpha_target', ALPHA_TARGET, episode)\n",
    "    policy.reset_optimizers()\n",
    "    for training_iteration in range(1, 100+1):\n",
    "        stats = train(policy, replay_buffer)\n",
    "        for stat, value in stats.items():\n",
    "            tb_writer.add_scalar(stat, value, episode)\n",
    "    if episode > 1000:\n",
    "        ALPHA_TARGET -= 0.3 / 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69afe679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [01:00<00:00,  6.05s/it]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "def render_only(initial_s, a, r, next_s, t, failed, limit):\n",
    "    env.render()\n",
    "\n",
    "for episode in tqdm.tqdm(range(1, 10+1)):\n",
    "    run_episode(action, render_only, env, policy)\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
