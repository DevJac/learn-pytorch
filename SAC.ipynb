{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2601a6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devjac/Code/python/learn-pytorch/.venv/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import namedtuple, deque\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf90475",
   "metadata": {},
   "outputs": [],
   "source": [
    "RENDER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f9a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.3             # How much we value entropy / exploration, increasing this will increase exploration.\n",
    "GAMMA = 1 - 0.01        # How much we value future rewards.\n",
    "TAU = 0.01              # How much q_target is updated when polyak averaging (step 15).\n",
    "POLICY_LR = 0.001       # Policy learning rate.\n",
    "Q_LR = 0.001            # Q learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf163657",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89982995",
   "metadata": {},
   "outputs": [],
   "source": [
    "SARS = namedtuple('SARS', 'state, action, reward, next_state, t, failed, limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2cd7e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=0)\n",
    "input = torch.tensor([1, 2, 3], dtype=float)\n",
    "display(input)\n",
    "output = softmax(input)\n",
    "display(output)\n",
    "sum(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ba09d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [3., 3., 3.]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652],\n",
       "        [0.3333, 0.3333, 0.3333]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5134, 0.8228, 1.6638], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "input = torch.tensor([[1, 2, 3], [1, 2, 3], [3, 3, 3]], dtype=float)\n",
    "display(input)\n",
    "output = softmax(input)\n",
    "display(output)\n",
    "sum(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e24dbb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, 1500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1500, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        nn_out = self.linear_relu_stack(x)\n",
    "        return nn.Softmax(dim=1)(nn_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        raise RuntimeError(\"Use forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357a97db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=2000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2000, out_features=1500, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1500, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_network = PolicyNetwork(4, 2)\n",
    "policy_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8763d75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c65c4c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57f14cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8173, 0.3151, 0.7515, 0.5986],\n",
       "        [0.4009, 0.6616, 0.5826, 0.1513],\n",
       "        [0.9163, 0.3828, 0.0130, 0.8971],\n",
       "        [0.9868, 0.0035, 0.2382, 0.9287],\n",
       "        [0.5092, 0.4537, 0.4599, 0.2654]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_states = torch.rand(5, 4)\n",
    "mock_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf6c7db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4749, 0.5251],\n",
       "        [0.4902, 0.5098],\n",
       "        [0.4454, 0.5546],\n",
       "        [0.4506, 0.5494],\n",
       "        [0.4820, 0.5180]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_network.forward(mock_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d287d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, 1500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1500, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        nn_out = self.linear_relu_stack(x)\n",
    "        return nn_out\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        raise RuntimeError(\"Use forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a80af706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=2000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2000, out_features=1500, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1500, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_network = QNetwork(4, 2)\n",
    "q_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e7c0e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0050, -0.0480],\n",
       "        [ 0.0081, -0.0944],\n",
       "        [-0.0104,  0.0221],\n",
       "        [-0.0133,  0.0398],\n",
       "        [-0.0079, -0.0611]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_network.forward(mock_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aeb9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(action_f, step_f, env, policy, fail_at_limit=False):\n",
    "    episode_reward = 0\n",
    "    s = env.reset()\n",
    "    for t in itertools.count(start=1):\n",
    "        a = action_f(policy, s)\n",
    "        next_state, reward, failed, info = env.step(a)\n",
    "        episode_reward += reward\n",
    "        assert t <= env._max_episode_steps\n",
    "        limit = t == env._max_episode_steps\n",
    "        if limit and not fail_at_limit:\n",
    "            failed = False\n",
    "        assert fail_at_limit or not (limit and failed)\n",
    "        step_f(s, a, reward, next_state, t, failed, limit)\n",
    "        if failed or limit:\n",
    "            break\n",
    "        s = next_state\n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e867c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    def __init__(self, env_state_size, env_action_space_size):\n",
    "        self.policy_network = PolicyNetwork(env_state_size, env_action_space_size)\n",
    "        self.q1_network = QNetwork(env_state_size, env_action_space_size)\n",
    "        self.q2_network = QNetwork(env_state_size, env_action_space_size)\n",
    "        self.q1_target_network = deepcopy(self.q1_network)\n",
    "        self.q2_target_network = deepcopy(self.q2_network)\n",
    "        self.policy_network.to(device)\n",
    "        self.q1_network.to(device)\n",
    "        self.q2_network.to(device)\n",
    "        self.q1_target_network.to(device)\n",
    "        self.q2_target_network.to(device)\n",
    "        self.reset_optimizers()\n",
    "\n",
    "    def reset_optimizers(self):\n",
    "        self.policy_optimizer = torch.optim.SGD(self.policy_network.parameters(), lr=POLICY_LR)\n",
    "        self.q1_optimizer = torch.optim.SGD(self.q1_network.parameters(), lr=Q_LR)\n",
    "        self.q2_optimizer = torch.optim.SGD(self.q2_network.parameters(), lr=Q_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2ef4891",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = deque(maxlen=30_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3835dfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3d9ddd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "856e3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "oss = env.observation_space.shape\n",
    "if len(oss) != 1:\n",
    "    raise RuntimeError(f'Unknown observation_space.shape: {oss}')\n",
    "os_len = oss[0]\n",
    "policy = Policy(os_len, env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26178da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00391579,  1.4190695 , -0.39665326,  0.36218733,  0.00454432,\n",
       "        0.08984792,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = env.reset()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c20fffdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0039,  1.4191, -0.3967,  0.3622,  0.0045,  0.0898,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.tensor(s).reshape((1, -1))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8200ac15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2533, 0.2375, 0.2402, 0.2690]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_output = policy.policy_network.forward(s.to(device))\n",
    "policy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3eb4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_weights = policy_output.reshape((-1,)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "481df43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b78db85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = random.choices(range(len(action_weights)), weights=action_weights)[0]\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a11637db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(policy, s):\n",
    "    tensor_s = torch.tensor(s).reshape((1, -1)).to(device)\n",
    "    action_weights = policy.policy_network.forward(tensor_s).reshape((-1,)).tolist()\n",
    "    action = random.choices(range(len(action_weights)), weights=action_weights)[0]\n",
    "    return action\n",
    "\n",
    "def step(initial_s, a, r, next_s, t, failed, limit):\n",
    "    replay_buffer.append(SARS(initial_s, a, r, next_s, t, failed, limit))\n",
    "    if RENDER:\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b642f7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-274.3197699814156"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_episode(action, step, env, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9107af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e377098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([SARS(state=array([-0.00770502,  1.4132539 , -0.78044456,  0.10368679,  0.00893491,\n",
       "               0.17678225,  0.        ,  0.        ], dtype=float32), action=1, reward=-1.9920909988097992, next_state=array([-0.01549768,  1.415017  , -0.7903069 ,  0.07825594,  0.01985907,\n",
       "               0.21850383,  0.        ,  0.        ], dtype=float32), t=1, failed=False, limit=False),\n",
       "       SARS(state=array([-0.01549768,  1.415017  , -0.7903069 ,  0.07825594,  0.01985907,\n",
       "               0.21850383,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0040721209665833, next_state=array([-0.02329063,  1.416182  , -0.7903408 ,  0.05159922,  0.03077668,\n",
       "               0.21837242,  0.        ,  0.        ], dtype=float32), t=2, failed=False, limit=False),\n",
       "       SARS(state=array([-0.02329063,  1.416182  , -0.7903408 ,  0.05159922,  0.03077668,\n",
       "               0.21837242,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.037461635782165, next_state=array([-0.03108406,  1.4167486 , -0.7903726 ,  0.02491999,  0.04169325,\n",
       "               0.21835157,  0.        ,  0.        ], dtype=float32), t=3, failed=False, limit=False),\n",
       "       SARS(state=array([-0.03108406,  1.4167486 , -0.7903726 ,  0.02491999,  0.04169325,\n",
       "               0.21835157,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.0716223796428608, next_state=array([-0.03887787,  1.4167169 , -0.7904042 , -0.00175664,  0.05260803,\n",
       "               0.2183158 ,  0.        ,  0.        ], dtype=float32), t=4, failed=False, limit=False),\n",
       "       SARS(state=array([-0.03887787,  1.4167169 , -0.7904042 , -0.00175664,  0.05260803,\n",
       "               0.2183158 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.1655309972068992, next_state=array([-0.04674025,  1.4160734 , -0.7989969 , -0.02909525,  0.06524865,\n",
       "               0.25283548,  0.        ,  0.        ], dtype=float32), t=5, failed=False, limit=False),\n",
       "       SARS(state=array([-0.04674025,  1.4160734 , -0.7989969 , -0.02909525,  0.06524865,\n",
       "               0.25283548,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3130485201147337, next_state=array([-0.0546031 ,  1.4148321 , -0.79903424, -0.05577537,  0.07788637,\n",
       "               0.25277793,  0.        ,  0.        ], dtype=float32), t=6, failed=False, limit=False),\n",
       "       SARS(state=array([-0.0546031 ,  1.4148321 , -0.79903424, -0.05577537,  0.07788637,\n",
       "               0.25277793,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.27648192890316525, next_state=array([-0.062393  ,  1.4129912 , -0.7898759 , -0.08241394,  0.08868333,\n",
       "               0.21595931,  0.        ,  0.        ], dtype=float32), t=7, failed=False, limit=False),\n",
       "       SARS(state=array([-0.062393  ,  1.4129912 , -0.7898759 , -0.08241394,  0.08868333,\n",
       "               0.21595931,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.5890605237539603, next_state=array([-0.07023153,  1.4116174 , -0.79479825, -0.06174162,  0.09954951,\n",
       "               0.21734333,  0.        ,  0.        ], dtype=float32), t=8, failed=False, limit=False),\n",
       "       SARS(state=array([-0.07023153,  1.4116174 , -0.79479825, -0.06174162,  0.09954951,\n",
       "               0.21734333,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.1844328858253448, next_state=array([-0.07807064,  1.4096448 , -0.79482746, -0.08842869,  0.11041347,\n",
       "               0.21729915,  0.        ,  0.        ], dtype=float32), t=9, failed=False, limit=False),\n",
       "       SARS(state=array([-0.07807064,  1.4096448 , -0.79482746, -0.08842869,  0.11041347,\n",
       "               0.21729915,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.4345786465470838, next_state=array([-0.08594207,  1.4081913 , -0.7982914 , -0.06545891,  0.12151369,\n",
       "               0.22202456,  0.        ,  0.        ], dtype=float32), t=10, failed=False, limit=False),\n",
       "       SARS(state=array([-0.08594207,  1.4081913 , -0.7982914 , -0.06545891,  0.12151369,\n",
       "               0.22202456,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5201737029792057, next_state=array([-0.09389763,  1.4061204 , -0.80884266, -0.09318304,  0.13475293,\n",
       "               0.26480943,  0.        ,  0.        ], dtype=float32), t=11, failed=False, limit=False),\n",
       "       SARS(state=array([-0.09389763,  1.4061204 , -0.80884266, -0.09318304,  0.13475293,\n",
       "               0.26480943,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4648222568903861, next_state=array([-0.10185385,  1.4034517 , -0.80888116, -0.1198628 ,  0.14798921,\n",
       "               0.26474985,  0.        ,  0.        ], dtype=float32), t=12, failed=False, limit=False),\n",
       "       SARS(state=array([-0.10185385,  1.4034517 , -0.80888116, -0.1198628 ,  0.14798921,\n",
       "               0.26474985,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.3355418613642758, next_state=array([-0.10973243,  1.4002056 , -0.7990697 , -0.14541723,  0.15920864,\n",
       "               0.22440843,  0.        ,  0.        ], dtype=float32), t=13, failed=False, limit=False),\n",
       "       SARS(state=array([-0.10973243,  1.4002056 , -0.7990697 , -0.14541723,  0.15920864,\n",
       "               0.22440843,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.3251642347057384, next_state=array([-0.11761151,  1.3963614 , -0.79909813, -0.17209817,  0.17042711,\n",
       "               0.22438979,  0.        ,  0.        ], dtype=float32), t=14, failed=False, limit=False),\n",
       "       SARS(state=array([-0.11761151,  1.3963614 , -0.79909813, -0.17209817,  0.17042711,\n",
       "               0.22438979,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.452096766632961, next_state=array([-0.1255621 ,  1.3919022 , -0.80804044, -0.19971578,  0.18346407,\n",
       "               0.26076263,  0.        ,  0.        ], dtype=float32), t=15, failed=False, limit=False),\n",
       "       SARS(state=array([-0.1255621 ,  1.3919022 , -0.80804044, -0.19971578,  0.18346407,\n",
       "               0.26076263,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5574184685218597, next_state=array([-0.13351336,  1.3868456 , -0.8080756 , -0.22640146,  0.19649814,\n",
       "               0.26070493,  0.        ,  0.        ], dtype=float32), t=16, failed=False, limit=False),\n",
       "       SARS(state=array([-0.13351336,  1.3868456 , -0.8080756 , -0.22640146,  0.19649814,\n",
       "               0.26070493,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.9049163170156078, next_state=array([-0.14153281,  1.3817283 , -0.8148716 , -0.2291975 ,  0.20954789,\n",
       "               0.26101887,  0.        ,  0.        ], dtype=float32), t=17, failed=False, limit=False),\n",
       "       SARS(state=array([-0.14153281,  1.3817283 , -0.8148716 , -0.2291975 ,  0.20954789,\n",
       "               0.26101887,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.523107725646837, next_state=array([-0.14948168,  1.3760436 , -0.80592334, -0.25426427,  0.22070768,\n",
       "               0.2232162 ,  0.        ,  0.        ], dtype=float32), t=18, failed=False, limit=False),\n",
       "       SARS(state=array([-0.14948168,  1.3760436 , -0.80592334, -0.25426427,  0.22070768,\n",
       "               0.2232162 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5685202718663322, next_state=array([-0.15737382,  1.3697878 , -0.7987016 , -0.27947882,  0.23032784,\n",
       "               0.1924204 ,  0.        ,  0.        ], dtype=float32), t=19, failed=False, limit=False),\n",
       "       SARS(state=array([-0.15737382,  1.3697878 , -0.7987016 , -0.27947882,  0.23032784,\n",
       "               0.1924204 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.5763923142501313, next_state=array([-0.16541882,  1.3640089 , -0.81404144, -0.25836173,  0.24001709,\n",
       "               0.19380285,  0.        ,  0.        ], dtype=float32), t=20, failed=False, limit=False),\n",
       "       SARS(state=array([-0.16541882,  1.3640089 , -0.81404144, -0.25836173,  0.24001709,\n",
       "               0.19380285,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.750997348718299, next_state=array([-0.17355776,  1.357587  , -0.82585555, -0.28741398,  0.25221187,\n",
       "               0.24391751,  0.        ,  0.        ], dtype=float32), t=21, failed=False, limit=False),\n",
       "       SARS(state=array([-0.17355776,  1.357587  , -0.82585555, -0.28741398,  0.25221187,\n",
       "               0.24391751,  0.        ,  0.        ], dtype=float32), action=2, reward=-0.6800912677701263, next_state=array([-0.18170795,  1.3515911 , -0.82766074, -0.26871422,  0.26514792,\n",
       "               0.258744  ,  0.        ,  0.        ], dtype=float32), t=22, failed=False, limit=False),\n",
       "       SARS(state=array([-0.18170795,  1.3515911 , -0.82766074, -0.26871422,  0.26514792,\n",
       "               0.258744  ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.4610699331599608, next_state=array([-0.18977948,  1.3450186 , -0.81776017, -0.29407007,  0.2760299 ,\n",
       "               0.21765964,  0.        ,  0.        ], dtype=float32), t=23, failed=False, limit=False),\n",
       "       SARS(state=array([-0.18977948,  1.3450186 , -0.81776017, -0.29407007,  0.2760299 ,\n",
       "               0.21765964,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.6747118814007422, next_state=array([-0.1979372 ,  1.3384587 , -0.82648003, -0.29362017,  0.28704342,\n",
       "               0.22028954,  0.        ,  0.        ], dtype=float32), t=24, failed=False, limit=False),\n",
       "       SARS(state=array([-0.1979372 ,  1.3384587 , -0.82648003, -0.29362017,  0.28704342,\n",
       "               0.22028954,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.3647380132585156, next_state=array([-0.20614234,  1.3312566 , -0.83307964, -0.3226135 ,  0.30000597,\n",
       "               0.25926   ,  0.        ,  0.        ], dtype=float32), t=25, failed=False, limit=False),\n",
       "       SARS(state=array([-0.20614234,  1.3312566 , -0.83307964, -0.3226135 ,  0.30000597,\n",
       "               0.25926   ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6326001494525144, next_state=array([-0.21435204,  1.3234437 , -0.83310825, -0.3497945 ,  0.3125666 ,\n",
       "               0.2512129 ,  0.        ,  0.        ], dtype=float32), t=26, failed=False, limit=False),\n",
       "       SARS(state=array([-0.21435204,  1.3234437 , -0.83310825, -0.3497945 ,  0.3125666 ,\n",
       "               0.2512129 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.022063142353022, next_state=array([-0.22292843,  1.3164699 , -0.869483  , -0.31254184,  0.32487866,\n",
       "               0.24624082,  0.        ,  0.        ], dtype=float32), t=27, failed=False, limit=False),\n",
       "       SARS(state=array([-0.22292843,  1.3164699 , -0.869483  , -0.31254184,  0.32487866,\n",
       "               0.24624082,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.5729791587163777, next_state=array([-0.23143688,  1.3089206 , -0.86093616, -0.33782524,  0.33540168,\n",
       "               0.21046028,  0.        ,  0.        ], dtype=float32), t=28, failed=False, limit=False),\n",
       "       SARS(state=array([-0.23143688,  1.3089206 , -0.86093616, -0.33782524,  0.33540168,\n",
       "               0.21046028,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.4086650122457627, next_state=array([-0.23994565,  1.3007725 , -0.8609315 , -0.3645008 ,  0.34592462,\n",
       "               0.21045837,  0.        ,  0.        ], dtype=float32), t=29, failed=False, limit=False),\n",
       "       SARS(state=array([-0.23994565,  1.3007725 , -0.8609315 , -0.3645008 ,  0.34592462,\n",
       "               0.21045837,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.5282849501149074, next_state=array([-0.24852605,  1.2919962 , -0.86986065, -0.39295232,  0.35835788,\n",
       "               0.24866445,  0.        ,  0.        ], dtype=float32), t=30, failed=False, limit=False),\n",
       "       SARS(state=array([-0.24852605,  1.2919962 , -0.86986065, -0.39295232,  0.35835788,\n",
       "               0.24866445,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6171468622696352, next_state=array([-0.25710693,  1.2826217 , -0.869854  , -0.4196312 ,  0.37079102,\n",
       "               0.24866219,  0.        ,  0.        ], dtype=float32), t=31, failed=False, limit=False),\n",
       "       SARS(state=array([-0.25710693,  1.2826217 , -0.869854  , -0.4196312 ,  0.37079102,\n",
       "               0.24866219,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6264034481915814, next_state=array([-0.26568827,  1.2726493 , -0.869847  , -0.44631004,  0.383224  ,\n",
       "               0.24866025,  0.        ,  0.        ], dtype=float32), t=32, failed=False, limit=False),\n",
       "       SARS(state=array([-0.26568827,  1.2726493 , -0.869847  , -0.44631004,  0.383224  ,\n",
       "               0.24866025,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6339628472737218, next_state=array([-0.27427015,  1.2620786 , -0.8698398 , -0.4729888 ,  0.39565694,\n",
       "               0.24865785,  0.        ,  0.        ], dtype=float32), t=33, failed=False, limit=False),\n",
       "       SARS(state=array([-0.27427015,  1.2620786 , -0.8698398 , -0.4729888 ,  0.39565694,\n",
       "               0.24865785,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6398364156033267, next_state=array([-0.28285256,  1.2509098 , -0.86983234, -0.49966753,  0.40808973,\n",
       "               0.24865513,  0.        ,  0.        ], dtype=float32), t=34, failed=False, limit=False),\n",
       "       SARS(state=array([-0.28285256,  1.2509098 , -0.86983234, -0.49966753,  0.40808973,\n",
       "               0.24865513,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6441222857491766, next_state=array([-0.29143548,  1.2391429 , -0.8698246 , -0.5263462 ,  0.42052236,\n",
       "               0.24865246,  0.        ,  0.        ], dtype=float32), t=35, failed=False, limit=False),\n",
       "       SARS(state=array([-0.29143548,  1.2391429 , -0.8698246 , -0.5263462 ,  0.42052236,\n",
       "               0.24865246,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.646840520913429, next_state=array([-0.30001903,  1.2267779 , -0.86981666, -0.5530247 ,  0.43295485,\n",
       "               0.24864984,  0.        ,  0.        ], dtype=float32), t=36, failed=False, limit=False),\n",
       "       SARS(state=array([-0.30001903,  1.2267779 , -0.86981666, -0.5530247 ,  0.43295485,\n",
       "               0.24864984,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7788814960595392, next_state=array([-0.3085433 ,  1.2138479 , -0.8622993 , -0.57774067,  0.44371134,\n",
       "               0.2151297 ,  0.        ,  0.        ], dtype=float32), t=37, failed=False, limit=False),\n",
       "       SARS(state=array([-0.3085433 ,  1.2138479 , -0.8622993 , -0.57774067,  0.44371134,\n",
       "               0.2151297 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.4408837832997847, next_state=array([-0.3171962 ,  1.2009277 , -0.8753575 , -0.5774606 ,  0.4547374 ,\n",
       "               0.22052088,  0.        ,  0.        ], dtype=float32), t=38, failed=False, limit=False),\n",
       "       SARS(state=array([-0.3171962 ,  1.2009277 , -0.8753575 , -0.5774606 ,  0.4547374 ,\n",
       "               0.22052088,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.528638248531847, next_state=array([-0.32591256,  1.1873643 , -0.88332766, -0.60668576,  0.46762136,\n",
       "               0.25767925,  0.        ,  0.        ], dtype=float32), t=39, failed=False, limit=False),\n",
       "       SARS(state=array([-0.32591256,  1.1873643 , -0.88332766, -0.60668576,  0.46762136,\n",
       "               0.25767925,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.9762628859542404, next_state=array([-0.334709  ,  1.1731424 , -0.89340335, -0.636793  ,  0.4828917 ,\n",
       "               0.3054072 ,  0.        ,  0.        ], dtype=float32), t=40, failed=False, limit=False),\n",
       "       SARS(state=array([-0.334709  ,  1.1731424 , -0.89340335, -0.636793  ,  0.4828917 ,\n",
       "               0.3054072 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.6653385543854984, next_state=array([-0.3434247 ,  1.158385  , -0.883031  , -0.6599499 ,  0.49570593,\n",
       "               0.25628465,  0.        ,  0.        ], dtype=float32), t=41, failed=False, limit=False),\n",
       "       SARS(state=array([-0.3434247 ,  1.158385  , -0.883031  , -0.6599499 ,  0.49570593,\n",
       "               0.25628465,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.968176568564813, next_state=array([-0.35222283,  1.1429722 , -0.8933296 , -0.68996596,  0.51093525,\n",
       "               0.30458614,  0.        ,  0.        ], dtype=float32), t=42, failed=False, limit=False),\n",
       "       SARS(state=array([-0.35222283,  1.1429722 , -0.8933296 , -0.68996596,  0.51093525,\n",
       "               0.30458614,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.1126623148695944, next_state=array([-0.36096758,  1.1269989 , -0.886484  , -0.7144774 ,  0.52457005,\n",
       "               0.27269566,  0.        ,  0.        ], dtype=float32), t=43, failed=False, limit=False),\n",
       "       SARS(state=array([-0.36096758,  1.1269989 , -0.886484  , -0.7144774 ,  0.52457005,\n",
       "               0.27269566,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.9141673258751826, next_state=array([-0.36965555,  1.1104661 , -0.8792442 , -0.73887026,  0.53651935,\n",
       "               0.2389876 ,  0.        ,  0.        ], dtype=float32), t=44, failed=False, limit=False),\n",
       "       SARS(state=array([-0.36965555,  1.1104661 , -0.8792442 , -0.73887026,  0.53651935,\n",
       "               0.2389876 ,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.585441560269544, next_state=array([-0.3783442 ,  1.0933349 , -0.8792351 , -0.7655472 ,  0.54846865,\n",
       "               0.23898523,  0.        ,  0.        ], dtype=float32), t=45, failed=False, limit=False),\n",
       "       SARS(state=array([-0.3783442 ,  1.0933349 , -0.8792351 , -0.7655472 ,  0.54846865,\n",
       "               0.23898523,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.40112914474187167, next_state=array([-0.38695627,  1.0756688 , -0.8694377 , -0.78854406,  0.55802065,\n",
       "               0.19103983,  0.        ,  0.        ], dtype=float32), t=46, failed=False, limit=False),\n",
       "       SARS(state=array([-0.38695627,  1.0756688 , -0.8694377 , -0.78854406,  0.55802065,\n",
       "               0.19103983,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.651254920311685, next_state=array([-0.39565152,  1.0573384 , -0.8798866 , -0.8190464 ,  0.57011414,\n",
       "               0.24186942,  0.        ,  0.        ], dtype=float32), t=47, failed=False, limit=False),\n",
       "       SARS(state=array([-0.39565152,  1.0573384 , -0.8798866 , -0.8190464 ,  0.57011414,\n",
       "               0.24186942,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.5836263495868934, next_state=array([-0.40434757,  1.0384096 , -0.8798768 , -0.8457235 ,  0.5822075 ,\n",
       "               0.24186702,  0.        ,  0.        ], dtype=float32), t=48, failed=False, limit=False),\n",
       "       SARS(state=array([-0.40434757,  1.0384096 , -0.8798768 , -0.8457235 ,  0.5822075 ,\n",
       "               0.24186702,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.672432543637426, next_state=array([-0.41310763,  1.018814  , -0.8880234 , -0.8762583 ,  0.59646654,\n",
       "               0.28517976,  0.        ,  0.        ], dtype=float32), t=49, failed=False, limit=False),\n",
       "       SARS(state=array([-0.41310763,  1.018814  , -0.8880234 , -0.8762583 ,  0.59646654,\n",
       "               0.28517976,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.7044072238379315, next_state=array([-0.42192507,  0.99856925, -0.8951454 , -0.90591854,  0.6125396 ,\n",
       "               0.32146055,  0.        ,  0.        ], dtype=float32), t=50, failed=False, limit=False),\n",
       "       SARS(state=array([-0.42192507,  0.99856925, -0.8951454 , -0.90591854,  0.6125396 ,\n",
       "               0.32146055,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.9534606966239494, next_state=array([-0.43074378,  0.9777274 , -0.8951268 , -0.9326031 ,  0.62861234,\n",
       "               0.32145482,  0.        ,  0.        ], dtype=float32), t=51, failed=False, limit=False),\n",
       "       SARS(state=array([-0.43074378,  0.9777274 , -0.8951268 , -0.9326031 ,  0.62861234,\n",
       "               0.32145482,  0.        ,  0.        ], dtype=float32), action=2, reward=-1.1031656326747907, next_state=array([-0.4397962 ,  0.95723176, -0.9190265 , -0.9177072 ,  0.6455253 ,\n",
       "               0.3382582 ,  0.        ,  0.        ], dtype=float32), t=52, failed=False, limit=False),\n",
       "       SARS(state=array([-0.4397962 ,  0.95723176, -0.9190265 , -0.9177072 ,  0.6455253 ,\n",
       "               0.3382582 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-0.7870616232804923, next_state=array([-0.44877106,  0.9362208 , -0.9089381 , -0.9396403 ,  0.6597478 ,\n",
       "               0.2844512 ,  0.        ,  0.        ], dtype=float32), t=53, failed=False, limit=False),\n",
       "       SARS(state=array([-0.44877106,  0.9362208 , -0.9089381 , -0.9396403 ,  0.6597478 ,\n",
       "               0.2844512 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.0544397469274416, next_state=array([-0.4578145 ,  0.9145231 , -0.91769475, -0.97135377,  0.6765236 ,\n",
       "               0.33551747,  0.        ,  0.        ], dtype=float32), t=54, failed=False, limit=False),\n",
       "       SARS(state=array([-0.4578145 ,  0.9145231 , -0.91769475, -0.97135377,  0.6765236 ,\n",
       "               0.33551747,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.0596571091333247, next_state=array([-0.46691197,  0.8921542 , -0.92452943, -1.0022211 ,  0.695359  ,\n",
       "               0.3767088 ,  0.        ,  0.        ], dtype=float32), t=55, failed=False, limit=False),\n",
       "       SARS(state=array([-0.46691197,  0.8921542 , -0.92452943, -1.0022211 ,  0.695359  ,\n",
       "               0.3767088 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.486997144872446, next_state=array([-0.4759663 ,  0.8692469 , -0.9186739 , -1.0255929 ,  0.7124951 ,\n",
       "               0.34272364,  0.        ,  0.        ], dtype=float32), t=56, failed=False, limit=False),\n",
       "       SARS(state=array([-0.4759663 ,  0.8692469 , -0.9186739 , -1.0255929 ,  0.7124951 ,\n",
       "               0.34272364,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.103356084352754, next_state=array([-0.48502237,  0.8457423 , -0.91864985, -1.0522784 ,  0.729631  ,\n",
       "               0.34271672,  0.        ,  0.        ], dtype=float32), t=57, failed=False, limit=False),\n",
       "       SARS(state=array([-0.48502237,  0.8457423 , -0.91864985, -1.0522784 ,  0.729631  ,\n",
       "               0.34271672,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.2956224341579332, next_state=array([-0.4940315 ,  0.8217011 , -0.91241896, -1.0754521 ,  0.74495625,\n",
       "               0.3065048 ,  0.        ,  0.        ], dtype=float32), t=58, failed=False, limit=False),\n",
       "       SARS(state=array([-0.4940315 ,  0.8217011 , -0.91241896, -1.0754521 ,  0.74495625,\n",
       "               0.3065048 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.483445104627026, next_state=array([-0.50367993,  0.79796404, -0.97598207, -1.0619246 ,  0.7599977 ,\n",
       "               0.30082923,  0.        ,  0.        ], dtype=float32), t=59, failed=False, limit=False),\n",
       "       SARS(state=array([-0.50367993,  0.79796404, -0.97598207, -1.0619246 ,  0.7599977 ,\n",
       "               0.30082923,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.711528009289668, next_state=array([-0.51374614,  0.7740369 , -1.0172081 , -1.0702305 ,  0.77451015,\n",
       "               0.2902485 ,  0.        ,  0.        ], dtype=float32), t=60, failed=False, limit=False),\n",
       "       SARS(state=array([-0.51374614,  0.7740369 , -1.0172081 , -1.0702305 ,  0.77451015,\n",
       "               0.2902485 ,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.9448986973397835, next_state=array([-0.5245445 ,  0.75063044, -1.0902755 , -1.0471938 ,  0.7890186 ,\n",
       "               0.29016808,  0.        ,  0.        ], dtype=float32), t=61, failed=False, limit=False),\n",
       "       SARS(state=array([-0.5245445 ,  0.75063044, -1.0902755 , -1.0471938 ,  0.7890186 ,\n",
       "               0.29016808,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.065734396871646, next_state=array([-0.5353971,  0.7265429, -1.0971391, -1.0786457,  0.8057768,\n",
       "               0.3351637,  0.       ,  0.       ], dtype=float32), t=62, failed=False, limit=False),\n",
       "       SARS(state=array([-0.5353971,  0.7265429, -1.0971391, -1.0786457,  0.8057768,\n",
       "               0.3351637,  0.       ,  0.       ], dtype=float32), action=1, reward=-3.1944898662203216, next_state=array([-0.5463031 ,  0.7017936 , -1.1036022 , -1.1091522 ,  0.82447547,\n",
       "               0.37397337,  0.        ,  0.        ], dtype=float32), t=63, failed=False, limit=False),\n",
       "       SARS(state=array([-0.5463031 ,  0.7017936 , -1.1036022 , -1.1091522 ,  0.82447547,\n",
       "               0.37397337,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.557684162973742, next_state=array([-0.55716103,  0.6765186 , -1.0971735 , -1.1316568 ,  0.84114486,\n",
       "               0.33338875,  0.        ,  0.        ], dtype=float32), t=64, failed=False, limit=False),\n",
       "       SARS(state=array([-0.55716103,  0.6765186 , -1.0971735 , -1.1316568 ,  0.84114486,\n",
       "               0.33338875,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.3205733132445516, next_state=array([-0.5680209 ,  0.65064615, -1.0971473 , -1.1583391 ,  0.85781395,\n",
       "               0.33338237,  0.        ,  0.        ], dtype=float32), t=65, failed=False, limit=False),\n",
       "       SARS(state=array([-0.5680209 ,  0.65064615, -1.0971473 , -1.1583391 ,  0.85781395,\n",
       "               0.33338237,  0.        ,  0.        ], dtype=float32), action=2, reward=-3.8312277518935955, next_state=array([-0.5792671 ,  0.6246547 , -1.1355448 , -1.1637185 ,  0.87443626,\n",
       "               0.33244595,  0.        ,  0.        ], dtype=float32), t=66, failed=False, limit=False),\n",
       "       SARS(state=array([-0.5792671 ,  0.6246547 , -1.1355448 , -1.1637185 ,  0.87443626,\n",
       "               0.33244595,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4370339139325097, next_state=array([-0.59051526,  0.5980657 , -1.1355182 , -1.1904002 ,  0.89105827,\n",
       "               0.33243972,  0.        ,  0.        ], dtype=float32), t=67, failed=False, limit=False),\n",
       "       SARS(state=array([-0.59051526,  0.5980657 , -1.1355182 , -1.1904002 ,  0.89105827,\n",
       "               0.33243972,  0.        ,  0.        ], dtype=float32), action=3, reward=-1.5052478085493977, next_state=array([-0.60171777,  0.5709676 , -1.1293063 , -1.2119198 ,  0.90538573,\n",
       "               0.28654873,  0.        ,  0.        ], dtype=float32), t=68, failed=False, limit=False),\n",
       "       SARS(state=array([-0.60171777,  0.5709676 , -1.1293063 , -1.2119198 ,  0.90538573,\n",
       "               0.28654873,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.5500205250072256, next_state=array([-0.61297697,  0.54317117, -1.1364167 , -1.2444607 ,  0.92233586,\n",
       "               0.339003  ,  0.        ,  0.        ], dtype=float32), t=69, failed=False, limit=False),\n",
       "       SARS(state=array([-0.61297697,  0.54317117, -1.1364167 , -1.2444607 ,  0.92233586,\n",
       "               0.339003  ,  0.        ,  0.        ], dtype=float32), action=1, reward=-3.677926517220014, next_state=array([-0.6242797 ,  0.5146887 , -1.1418607 , -1.276263  ,  0.94148856,\n",
       "               0.38305378,  0.        ,  0.        ], dtype=float32), t=70, failed=False, limit=False),\n",
       "       SARS(state=array([-0.6242797 ,  0.5146887 , -1.1418607 , -1.276263  ,  0.94148856,\n",
       "               0.38305378,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.9879893557845207, next_state=array([-0.63558507,  0.48560908, -1.1418235 , -1.3029481 ,  0.9606408 ,\n",
       "               0.38304412,  0.        ,  0.        ], dtype=float32), t=71, failed=False, limit=False),\n",
       "       SARS(state=array([-0.63558507,  0.48560908, -1.1418235 , -1.3029481 ,  0.9606408 ,\n",
       "               0.38304412,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.284189287970974, next_state=array([-0.6469377 ,  0.45581704, -1.1478026 , -1.3363016 ,  0.9825466 ,\n",
       "               0.4381166 ,  0.        ,  0.        ], dtype=float32), t=72, failed=False, limit=False),\n",
       "       SARS(state=array([-0.6469377 ,  0.45581704, -1.1478026 , -1.3363016 ,  0.9825466 ,\n",
       "               0.4381166 ,  0.        ,  0.        ], dtype=float32), action=3, reward=-2.341554732490151, next_state=array([-0.65825045,  0.42554206, -1.1419177 , -1.3563963 ,  1.001732  ,\n",
       "               0.38370702,  0.        ,  0.        ], dtype=float32), t=73, failed=False, limit=False),\n",
       "       SARS(state=array([-0.65825045,  0.42554206, -1.1419177 , -1.3563963 ,  1.001732  ,\n",
       "               0.38370702,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.440015927493646, next_state=array([-0.66960573,  0.39455804, -1.1472591 , -1.3895594 ,  1.0235583 ,\n",
       "               0.43652505,  0.        ,  0.        ], dtype=float32), t=74, failed=False, limit=False),\n",
       "       SARS(state=array([-0.66960573,  0.39455804, -1.1472591 , -1.3895594 ,  1.0235583 ,\n",
       "               0.43652505,  0.        ,  0.        ], dtype=float32), action=0, reward=-3.6911614923334355, next_state=array([-0.6809646 ,  0.36297736, -1.1472082 , -1.4162475 ,  1.0453838 ,\n",
       "               0.4365109 ,  0.        ,  0.        ], dtype=float32), t=75, failed=False, limit=False),\n",
       "       SARS(state=array([-0.6809646 ,  0.36297736, -1.1472082 , -1.4162475 ,  1.0453838 ,\n",
       "               0.4365109 ,  0.        ,  0.        ], dtype=float32), action=1, reward=-4.713920057284581, next_state=array([-0.6923612 ,  0.33071697, -1.1515563 , -1.4478245 ,  1.0692472 ,\n",
       "               0.47726884,  0.        ,  0.        ], dtype=float32), t=76, failed=False, limit=False),\n",
       "       SARS(state=array([-0.6923612 ,  0.33071697, -1.1515563 , -1.4478245 ,  1.0692472 ,\n",
       "               0.47726884,  0.        ,  0.        ], dtype=float32), action=2, reward=-6.913296175800656, next_state=array([-0.70458233,  0.29871827, -1.2337439 , -1.4366765 ,  1.0936056 ,\n",
       "               0.48716837,  0.        ,  0.        ], dtype=float32), t=77, failed=False, limit=False),\n",
       "       SARS(state=array([-0.70458233,  0.29871827, -1.2337439 , -1.4366765 ,  1.0936056 ,\n",
       "               0.48716837,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.520515716150014, next_state=array([-0.71677244,  0.26621062, -1.2291383 , -1.4581699 ,  1.1158035 ,\n",
       "               0.44395575,  0.        ,  0.        ], dtype=float32), t=78, failed=False, limit=False),\n",
       "       SARS(state=array([-0.71677244,  0.26621062, -1.2291383 , -1.4581699 ,  1.1158035 ,\n",
       "               0.44395575,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.164637414899316, next_state=array([-0.7289223 ,  0.23322602, -1.2234247 , -1.4777311 ,  1.1350875 ,\n",
       "               0.38568085,  0.        ,  0.        ], dtype=float32), t=79, failed=False, limit=False),\n",
       "       SARS(state=array([-0.7289223 ,  0.23322602, -1.2234247 , -1.4777311 ,  1.1350875 ,\n",
       "               0.38568085,  0.        ,  0.        ], dtype=float32), action=3, reward=6.91569418930547, next_state=array([-0.7410355 ,  0.19976178, -1.2182486 , -1.4974074 ,  1.1515409 ,\n",
       "               0.3290674 ,  0.        ,  1.        ], dtype=float32), t=80, failed=False, limit=False),\n",
       "       SARS(state=array([-0.7410355 ,  0.19976178, -1.2182486 , -1.4974074 ,  1.1515409 ,\n",
       "               0.3290674 ,  0.        ,  1.        ], dtype=float32), action=3, reward=8.271203464776052, next_state=array([-0.75161976,  0.17858599, -1.1312296 , -1.1283196 ,  1.3961065 ,\n",
       "               4.6011457 ,  0.        ,  1.        ], dtype=float32), t=81, failed=False, limit=False),\n",
       "       SARS(state=array([-0.75161976,  0.17858599, -1.1312296 , -1.1283196 ,  1.3961065 ,\n",
       "               4.6011457 ,  0.        ,  1.        ], dtype=float32), action=2, reward=-23.1414662215543, next_state=array([-0.7634018 ,  0.1611783 , -1.1882186 , -0.98124516,  1.6735705 ,\n",
       "               5.4638934 ,  0.        ,  1.        ], dtype=float32), t=82, failed=False, limit=False),\n",
       "       SARS(state=array([-0.7634018 ,  0.1611783 , -1.1882186 , -0.98124516,  1.6735705 ,\n",
       "               5.4638934 ,  0.        ,  1.        ], dtype=float32), action=2, reward=-100, next_state=array([-0.7743176 ,  0.16502753, -1.0214523 ,  0.23232695,  1.8437545 ,\n",
       "               2.8765042 ,  0.        ,  1.        ], dtype=float32), t=83, failed=True, limit=False)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88986d2",
   "metadata": {},
   "source": [
    "# Polyak Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "131ea41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2818, -0.1534, -0.0185,  ..., -0.2867, -0.2902, -0.1200],\n",
       "        [-0.0851,  0.0455,  0.1821,  ...,  0.2526, -0.1581,  0.1606],\n",
       "        [-0.1401,  0.2872, -0.3022,  ..., -0.2287, -0.0575, -0.2660],\n",
       "        ...,\n",
       "        [ 0.2737, -0.2306, -0.3291,  ...,  0.1814,  0.3081, -0.1547],\n",
       "        [ 0.3150, -0.2740,  0.2353,  ...,  0.2184,  0.2793,  0.1959],\n",
       "        [-0.3047, -0.1932, -0.2062,  ...,  0.2474, -0.3462,  0.2167]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parameter_1 = next(policy.policy_network.named_parameters())[1]\n",
    "test_parameter_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52883c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        ...,\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128],\n",
       "        [0.0128, 0.0128, 0.0128,  ..., 0.0128, 0.0128, 0.0128]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parameter_2 = test_parameter_1 * 0 + 0.0128\n",
    "test_parameter_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f54a772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2523, -0.1368, -0.0153,  ..., -0.2568, -0.2599, -0.1067],\n",
       "        [-0.0753,  0.0423,  0.1652,  ...,  0.2287, -0.1410,  0.1458],\n",
       "        [-0.1248,  0.2597, -0.2707,  ..., -0.2046, -0.0505, -0.2382],\n",
       "        ...,\n",
       "        [ 0.2476, -0.2063, -0.2949,  ...,  0.1646,  0.2786, -0.1379],\n",
       "        [ 0.2848, -0.2453,  0.2131,  ...,  0.1978,  0.2526,  0.1776],\n",
       "        [-0.2729, -0.1726, -0.1843,  ...,  0.2239, -0.3103,  0.1963]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parameter_1 * 0.9 + test_parameter_2 * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83a08ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyak_update(network_to_update, target_network, tau=0.001):\n",
    "    with torch.no_grad():\n",
    "        for to_update, target in zip(network_to_update.parameters(), target_network.parameters()):\n",
    "            to_update *= 1-tau\n",
    "            to_update += target * tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8cc28e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0741, -0.1410, -0.1811, -0.3515, -0.3451],\n",
       "        [-0.2800,  0.4027, -0.4254,  0.0194, -0.2672],\n",
       "        [ 0.0916, -0.2298, -0.0562,  0.3056,  0.1465],\n",
       "        ...,\n",
       "        [ 0.3771, -0.3419, -0.0322,  0.2105,  0.4407],\n",
       "        [-0.2593, -0.1618, -0.3870,  0.4451, -0.2519],\n",
       "        [-0.2275,  0.2986,  0.3021,  0.0071,  0.2386]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1611,  0.0708,  0.0283,  0.3144,  0.3004],\n",
       "        [ 0.1640,  0.0361,  0.2048,  0.4455, -0.3690],\n",
       "        [-0.0309,  0.3177, -0.3345,  0.2461, -0.2685],\n",
       "        ...,\n",
       "        [ 0.1074, -0.0733, -0.2744, -0.0081,  0.0439],\n",
       "        [ 0.4372,  0.0680,  0.2465,  0.1044,  0.3385],\n",
       "        [ 0.0889,  0.4237,  0.0940, -0.2569,  0.1042]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0741, -0.1410, -0.1811, -0.3515, -0.3451],\n",
       "        [-0.2800,  0.4027, -0.4254,  0.0194, -0.2672],\n",
       "        [ 0.0916, -0.2298, -0.0562,  0.3056,  0.1465],\n",
       "        ...,\n",
       "        [ 0.3771, -0.3419, -0.0322,  0.2105,  0.4407],\n",
       "        [-0.2593, -0.1618, -0.3870,  0.4451, -0.2519],\n",
       "        [-0.2275,  0.2986,  0.3021,  0.0071,  0.2386]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1524,  0.0496,  0.0073,  0.2478,  0.2358],\n",
       "        [ 0.1196,  0.0728,  0.1418,  0.4029, -0.3588],\n",
       "        [-0.0186,  0.2630, -0.3067,  0.2520, -0.2270],\n",
       "        ...,\n",
       "        [ 0.1344, -0.1001, -0.2501,  0.0137,  0.0835],\n",
       "        [ 0.3675,  0.0450,  0.1831,  0.1384,  0.2795],\n",
       "        [ 0.0572,  0.4112,  0.1148, -0.2305,  0.1176]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_network_1 = QNetwork(5, 3)\n",
    "test_network_2 = QNetwork(5, 3)\n",
    "display(list(test_network_1.parameters())[0])\n",
    "display(list(test_network_2.parameters())[0])\n",
    "polyak_update(test_network_2, test_network_1, 0.1)\n",
    "display(list(test_network_1.parameters())[0])\n",
    "display(list(test_network_2.parameters())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a6271",
   "metadata": {},
   "source": [
    "# Log Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d9242c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.01005034, 4.60517019])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.615220521841592"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.10536052, 2.30258509])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.4079456086518722"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.22314355, 1.60943791])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.8325814637483102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.51082562, 0.91629073])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.4271163556401456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.69314718, 0.69314718])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.3862943611198906"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for p in [0.99, 0.9, 0.8, 0.6, 0.5]:\n",
    "    logs = -np.log([p, 1-p])\n",
    "    display(p, logs, sum(logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e37d9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SARS(state=array([-0.28285256,  1.2509098 , -0.86983234, -0.49966753,  0.40808973,\n",
       "         0.24865513,  0.        ,  0.        ], dtype=float32), action=0, reward=-1.6441222857491766, next_state=array([-0.29143548,  1.2391429 , -0.8698246 , -0.5263462 ,  0.42052236,\n",
       "         0.24865246,  0.        ,  0.        ], dtype=float32), t=35, failed=False, limit=False),\n",
       " SARS(state=array([-0.5792671 ,  0.6246547 , -1.1355448 , -1.1637185 ,  0.87443626,\n",
       "         0.33244595,  0.        ,  0.        ], dtype=float32), action=0, reward=-2.4370339139325097, next_state=array([-0.59051526,  0.5980657 , -1.1355182 , -1.1904002 ,  0.89105827,\n",
       "         0.33243972,  0.        ,  0.        ], dtype=float32), t=67, failed=False, limit=False),\n",
       " SARS(state=array([-0.70458233,  0.29871827, -1.2337439 , -1.4366765 ,  1.0936056 ,\n",
       "         0.48716837,  0.        ,  0.        ], dtype=float32), action=3, reward=-3.520515716150014, next_state=array([-0.71677244,  0.26621062, -1.2291383 , -1.4581699 ,  1.1158035 ,\n",
       "         0.44395575,  0.        ,  0.        ], dtype=float32), t=78, failed=False, limit=False),\n",
       " SARS(state=array([-0.41310763,  1.018814  , -0.8880234 , -0.8762583 ,  0.59646654,\n",
       "         0.28517976,  0.        ,  0.        ], dtype=float32), action=1, reward=-2.7044072238379315, next_state=array([-0.42192507,  0.99856925, -0.8951454 , -0.90591854,  0.6125396 ,\n",
       "         0.32146055,  0.        ,  0.        ], dtype=float32), t=50, failed=False, limit=False)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(replay_buffer, k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4199269",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "![Psudocode](sac_psudocode.png)\n",
    "\n",
    "Source: https://spinningup.openai.com/en/latest/algorithms/sac.html#pseudocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8998ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_min(q1, q2, states):\n",
    "    \n",
    "    def f(q):\n",
    "        state_values = q.forward(states.to(device)).detach()\n",
    "        return state_values\n",
    "        \n",
    "    return torch.minimum(*map(f, (q1, q2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "856452ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train/q_loss_1': tensor(131.5877, device='cuda:0', dtype=torch.float64),\n",
       " 'train/q_loss_2': tensor(131.0647, device='cuda:0', dtype=torch.float64),\n",
       " 'train/policy_loss': tensor(-0.2658, device='cuda:0')}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    stats = {}\n",
    "    # Step 11\n",
    "    training_batch = random.sample(replay_buffer, k=min(len(replay_buffer), 100))\n",
    "    # Prep\n",
    "    states = torch.tensor(np.array([sars.state for sars in training_batch]), requires_grad=False).to(device)\n",
    "    actions = torch.tensor(np.array([sars.action for sars in training_batch]), requires_grad=False).to(device)\n",
    "    actions_hot = nn.functional.one_hot(actions, env.action_space.n).to(device)\n",
    "    rewards = torch.tensor(np.array([sars.reward for sars in training_batch]), requires_grad=False).to(device)\n",
    "    next_states = torch.tensor(np.array([sars.next_state for sars in training_batch]), requires_grad=False).to(device)\n",
    "    fails = torch.tensor(np.array([sars.failed for sars in training_batch]), dtype=int, requires_grad=False).to(device)\n",
    "    # Step 12\n",
    "    next_action_probs = policy.policy_network.forward(next_states.to(device)).detach()\n",
    "    assert not next_action_probs.requires_grad\n",
    "    next_states_q_min = q_min(policy.q1_target_network, policy.q2_target_network, next_states)\n",
    "    assert not next_states_q_min.requires_grad\n",
    "    next_actions_q_min = torch.sum(next_states_q_min * next_action_probs, 1)\n",
    "    assert not next_actions_q_min.requires_grad\n",
    "    next_actions_entropy = torch.sum(next_action_probs * torch.log(next_action_probs), 1)\n",
    "    assert not next_actions_entropy.requires_grad\n",
    "    y = rewards + GAMMA * (1-fails) * (next_actions_q_min - ALPHA * next_actions_entropy)\n",
    "    assert not y.requires_grad\n",
    "    # Step 13\n",
    "    for qi, q, opt in ((1, policy.q1_network, policy.q1_optimizer),\n",
    "                       (2, policy.q2_network, policy.q2_optimizer)):\n",
    "        assert not states.requires_grad\n",
    "        assert not actions_hot.requires_grad\n",
    "        q_state_action = torch.sum(q.forward(states.to(device)) * actions_hot, 1)\n",
    "        assert q_state_action.requires_grad\n",
    "        q_loss = torch.mean((q_state_action - y)**2)\n",
    "        stats[f'train/q_loss_{qi}'] = q_loss.detach()\n",
    "        assert q_loss.requires_grad\n",
    "        opt.zero_grad()\n",
    "        q_loss.backward()\n",
    "        opt.step()\n",
    "    # Step 14\n",
    "    action_probs = policy.policy_network.forward(states)\n",
    "    assert action_probs.requires_grad\n",
    "    states_q_min = q_min(policy.q1_network, policy.q2_network, states)\n",
    "    assert not states_q_min.requires_grad\n",
    "    actions_q_min = torch.sum(states_q_min * action_probs, 1)\n",
    "    assert actions_q_min.requires_grad\n",
    "    actions_entropy = torch.sum(action_probs * torch.log(action_probs), 1)\n",
    "    assert actions_entropy.requires_grad\n",
    "    policy_loss = -1 * torch.mean(actions_q_min - ALPHA * actions_entropy)\n",
    "    stats['train/policy_loss'] = policy_loss.detach()\n",
    "    policy.policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy.policy_optimizer.step()\n",
    "    # Step 15\n",
    "    polyak_update(policy.q1_target_network, policy.q1_network, tau=TAU)\n",
    "    polyak_update(policy.q2_target_network, policy.q2_network, tau=TAU)\n",
    "    stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ef3f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(policy, replay_buffer):\n",
    "    stats = {}\n",
    "    # Step 11\n",
    "    training_batch = random.sample(replay_buffer, k=min(len(replay_buffer), 100))\n",
    "    # Prep\n",
    "    states = torch.tensor(np.array([sars.state for sars in training_batch]), requires_grad=False).to(device)\n",
    "    actions = torch.tensor(np.array([sars.action for sars in training_batch]), requires_grad=False).to(device)\n",
    "    actions_hot = nn.functional.one_hot(actions, env.action_space.n).to(device)\n",
    "    rewards = torch.tensor(np.array([sars.reward for sars in training_batch]), requires_grad=False).to(device)\n",
    "    next_states = torch.tensor(np.array([sars.next_state for sars in training_batch]), requires_grad=False).to(device)\n",
    "    fails = torch.tensor(np.array([sars.failed for sars in training_batch]), dtype=int, requires_grad=False).to(device)\n",
    "    # Step 12\n",
    "    next_action_probs = policy.policy_network.forward(next_states.to(device)).detach()\n",
    "    assert not next_action_probs.requires_grad\n",
    "    next_states_q_min = q_min(policy.q1_target_network, policy.q2_target_network, next_states)\n",
    "    assert not next_states_q_min.requires_grad\n",
    "    next_actions_q_min = torch.sum(next_states_q_min * next_action_probs, 1)\n",
    "    assert not next_actions_q_min.requires_grad\n",
    "    next_actions_entropy = torch.sum(next_action_probs * torch.log(next_action_probs), 1)\n",
    "    assert not next_actions_entropy.requires_grad\n",
    "    y = rewards + GAMMA * (1-fails) * (next_actions_q_min - ALPHA * next_actions_entropy)\n",
    "    assert not y.requires_grad\n",
    "    # Step 13\n",
    "    for qi, q, opt in ((1, policy.q1_network, policy.q1_optimizer),\n",
    "                       (2, policy.q2_network, policy.q2_optimizer)):\n",
    "        assert not states.requires_grad\n",
    "        assert not actions_hot.requires_grad\n",
    "        q_state_action = torch.sum(q.forward(states.to(device)) * actions_hot, 1)\n",
    "        assert q_state_action.requires_grad\n",
    "        q_loss = torch.mean((q_state_action - y)**2)\n",
    "        stats[f'train/q_loss_{qi}'] = q_loss.detach()\n",
    "        assert q_loss.requires_grad\n",
    "        opt.zero_grad()\n",
    "        q_loss.backward()\n",
    "        opt.step()\n",
    "    # Step 14\n",
    "    action_probs = policy.policy_network.forward(states)\n",
    "    assert action_probs.requires_grad\n",
    "    states_q_min = q_min(policy.q1_network, policy.q2_network, states)\n",
    "    assert not states_q_min.requires_grad\n",
    "    actions_q_min = torch.sum(states_q_min * action_probs, 1)\n",
    "    assert actions_q_min.requires_grad\n",
    "    actions_entropy = torch.sum(action_probs * torch.log(action_probs), 1)\n",
    "    assert actions_entropy.requires_grad\n",
    "    policy_loss = -1 * torch.mean(actions_q_min - ALPHA * actions_entropy)\n",
    "    stats['train/policy_loss'] = policy_loss.detach()\n",
    "    policy.policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy.policy_optimizer.step()\n",
    "    # Step 15\n",
    "    polyak_update(policy.q1_target_network, policy.q1_network, tau=TAU)\n",
    "    polyak_update(policy.q2_target_network, policy.q2_network, tau=TAU)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96080451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3000/3000 [52:14<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "tb_writer = SummaryWriter()\n",
    "\n",
    "oss = env.observation_space.shape\n",
    "if len(oss) != 1:\n",
    "    raise RuntimeError(f'Unknown observation_space.shape: {oss}')\n",
    "os_len = oss[0]\n",
    "policy = Policy(os_len, env.action_space.n)\n",
    "\n",
    "replay_buffer = deque(maxlen=30_000)\n",
    "\n",
    "def action(policy, s):\n",
    "    tensor_s = torch.tensor(s).reshape((1, -1))\n",
    "    action_weights = policy.policy_network.forward(tensor_s.to(device)).reshape((-1,)).tolist()\n",
    "    action = random.choices(range(len(action_weights)), weights=action_weights)[0]\n",
    "    return action\n",
    "\n",
    "def step(initial_s, a, r, next_s, t, failed, limit):\n",
    "    replay_buffer.append(SARS(initial_s, a, r, next_s, t, failed, limit))\n",
    "    if RENDER:\n",
    "        env.render()\n",
    "\n",
    "for episode in tqdm.tqdm(range(1, 3000+1)):\n",
    "    episode_reward = run_episode(action, step, env, policy, fail_at_limit=True)\n",
    "    tb_writer.add_scalar('main/episode_reward', episode_reward, episode)\n",
    "    tb_writer.add_scalar('main/replay_buffer_length', len(replay_buffer), episode)\n",
    "    policy.reset_optimizers()\n",
    "    for training_iteration in range(1, 100+1):\n",
    "        stats = train(policy, replay_buffer)\n",
    "        for stat, value in stats.items():\n",
    "            tb_writer.add_scalar(stat, value, episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69afe679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|           | 9/10 [02:34<00:19, 19.36s/it]"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "def render_only(initial_s, a, r, next_s, t, failed, limit):\n",
    "    env.render()\n",
    "\n",
    "for episode in tqdm.tqdm(range(1, 10+1)):\n",
    "    run_episode(action, render_only, env, policy)\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
